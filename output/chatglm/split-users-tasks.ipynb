{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91975d07-bb25-46a8-9a2b-5444042e975c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51108712-78b6-4b0f-bf9f-4bf5457494b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/mymusise/ChatGLM-Tuning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2445bd-67e2-438b-af7b-5a2d2de2c9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T02:02:20.724785Z",
     "iopub.status.busy": "2023-04-08T02:02:20.724196Z",
     "iopub.status.idle": "2023-04-08T02:02:20.731817Z",
     "shell.execute_reply": "2023-04-08T02:02:20.730842Z",
     "shell.execute_reply.started": "2023-04-08T02:02:20.724751Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/ChatGLM-Tuning\n"
     ]
    }
   ],
   "source": [
    "%cd ChatGLM-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df96169-9820-44ad-b8fd-9020a7b74829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T02:02:22.691282Z",
     "iopub.status.busy": "2023-04-08T02:02:22.690804Z",
     "iopub.status.idle": "2023-04-08T02:02:43.003061Z",
     "shell.execute_reply": "2023-04-08T02:02:43.001964Z",
     "shell.execute_reply.started": "2023-04-08T02:02:22.691261Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08 (from -r requirements.txt (line 16))\n",
      "  Cloning https://github.com/huggingface/peft.git (to revision e536616888d51b453ed354a6f1e243fecb02ea08) to /tmp/pip-req-build-2vf9v8o2\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-2vf9v8o2\n",
      "  Running command git rev-parse -q --verify 'sha^e536616888d51b453ed354a6f1e243fecb02ea08'\n",
      "  Running command git fetch -q https://github.com/huggingface/peft.git e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Running command git checkout -q e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Resolved https://github.com/huggingface/peft.git to commit e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bitsandbytes==0.37.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ec/18/75dbd7529844c8600944df123160216323982d39d24a30e9f6806279f935/bitsandbytes-0.37.1-py3-none-any.whl (76.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==0.17.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0a/ca/96a50d122bd07d06c66e20e6bd275b5c8829602398f4e141f8755a25e31e/accelerate-0.17.1-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20.1,>=3.19.5\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/88/88/cd55f87e896b82a3aba8e6c0affc077de51f7321cf730622b17ef7b0f69c/protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.27.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6d/9b/2f536f9e73390209e0b27b74691355dac494b7ec8154f3012fdc6debbae7/transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting icetk\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/8a/731927e0901273815b779e6ce0e081a95ecf78835ff80be30830505ae06c/icetk-0.0.7-py3-none-any.whl (16 kB)\n",
      "Collecting cpm_kernels==1.0.11\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/af/84/1831ce6ffa87b8fd4d9673c3595d0fc4e6631c0691eb43f406d3bf89b951/cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (1.13.1+cu117)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (2.2.0)\n",
      "Collecting datasets==2.10.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/17/5825fdf034ff1a315becdbb9b6fe5a2bd9d8e724464535f18809593bf9c2/datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m127.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (1.23.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/site-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (23.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/site-packages (from accelerate==0.17.1->-r requirements.txt (line 3)) (5.9.4)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/74/71/abf5df0be7a29b6920d4ae85eb685584afbe84610631b70fe366b2857801/regex-2023.3.23-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/90/5ad98abead047169f4f86bc67e99020c841d71c9c6bd202e04af71e70e53/huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (4.64.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4e/f2/017bf57106b845e31ef6179bf204042720a53629cf599ef9464da990e0e5/tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m149.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9e/6b/fdcd53aeee771a868c4187f0955116894a2b1e82d73fb5990c2ef63afc18/filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from transformers==4.27.1->-r requirements.txt (line 7)) (2.28.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from datasets==2.10.1->-r requirements.txt (line 14)) (1.5.2)\n",
      "Collecting multiprocess\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/13/95/8b875a678c6f9db81809dd5d6032e9f8628426e37f6aa6b7d404ba582de1/multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/be/e3/a84bf2e561beed15813080d693b4b27573262433fced9c1d1fea59e60553/dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1a/d7/a42f83d34d4999321e06ca273f5e7bf7fa177154e29e0bfe455f3c66648d/xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d2/e5/cef5eeb11d7e8bac830b3bee1c8311b19bf8e8a1c45fe14b876c70adcd06/aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.11.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4f/65/887925f1549fcb6ac3abb23a747c10f5ab083e8471fe568768b18bdb15b2/fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=6.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5d/91/708bcf6e636fc4f1a07bdb704c0a320bafe9b83919cd501648307b31f555/pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0e/7e/a69d054029c7c0470e490b3265bbd1497df9492599b1820b9d5be2c60444/sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/site-packages (from icetk->-r requirements.txt (line 8)) (0.14.1+cu117)\n",
      "Collecting icetk\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ca/eb/db3b8d7e891a959bd53641019f7b7e0ece6bfe9d89a6316d011bb6e0afd2/icetk-0.0.6-py3-none-any.whl (15 kB)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1e/21/4dc97f0ffc0b833dd3bf667e214e65f98fc361af56a82b34039383a9e05c/icetk-0.0.5-py3-none-any.whl (15 kB)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/c6/1fe059fff5d532122b5a93be15b23bc9eedb5e0eda24d51ae9e389584f17/icetk-0.0.4-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torch>=1.13.1->-r requirements.txt (line 10)) (4.4.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (1.51.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (65.6.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (1.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (1.35.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 11)) (0.4.6)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b3/0d/0ba1f2022b9a36ae670c1f3c579ed08d0958398cb6beaf4687e606ad33d4/yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.1/262.1 kB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14)) (2.0.4)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/0c/8469202f8f4b0e65816f91c3febc4bda7316c995b59ecdf3b15c574f7a24/multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 14)) (22.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ec/ab/a440db757401a1e8863c9abb374a77cb2884eda74ffbf555dedcf1fbe7f6/frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (6.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->transformers==4.27.1->-r requirements.txt (line 7)) (2022.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard->-r requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/site-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 14)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 14)) (2022.7)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/site-packages (from torchvision->icetk->-r requirements.txt (line 8)) (9.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 11)) (3.2.2)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=41645 sha256=531ba954b6b6abb2f17f2dced23e2587baf743b12b5b06bb1e034929e08ebe6f\n",
      "  Stored in directory: /root/.cache/pip/wheels/da/70/31/9924c81a28479a21d715f7bfae13723f624e706d93b97c4b78\n",
      "Successfully built peft\n",
      "Installing collected packages: tokenizers, sentencepiece, cpm_kernels, bitsandbytes, xxhash, regex, pyarrow, protobuf, multidict, fsspec, frozenlist, filelock, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, accelerate, transformers, icetk, aiohttp, peft, datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "onnx 1.13.0 requires protobuf<4,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.17.1 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bitsandbytes-0.37.1 cpm_kernels-1.0.11 datasets-2.10.1 dill-0.3.6 filelock-3.11.0 frozenlist-1.3.3 fsspec-2023.3.0 huggingface-hub-0.13.4 icetk-0.0.4 multidict-6.0.4 multiprocess-0.70.14 peft-0.3.0.dev0 protobuf-3.20.0 pyarrow-11.0.0 regex-2023.3.23 responses-0.18.0 sentencepiece-0.1.97 tokenizers-0.13.3 transformers-4.27.1 xxhash-3.2.0 yarl-1.8.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec15008-542b-4f49-a7bf-7e3c43db3fbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 准备数据\n",
    "## cover_alpaca2jsonl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a296d5-38b0-4dff-95b4-83c0610ec42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T02:03:18.920876Z",
     "iopub.status.busy": "2023-04-08T02:03:18.920438Z",
     "iopub.status.idle": "2023-04-08T02:03:18.950058Z",
     "shell.execute_reply": "2023-04-08T02:03:18.949189Z",
     "shell.execute_reply.started": "2023-04-08T02:03:18.920840Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "formatting..: 100%|██████████| 186/186 [00:00<00:00, 36562.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: create userstory tasks \\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    return {\"context\": context, \"target\": target}\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(\"/openbayes/input/input0/datasets/userstory_map.jsonl\") as f:\n",
    "        examples = list(f)\n",
    "\n",
    "    with open(\"/output/train.jsonl\", 'w') as f:\n",
    "        for example in tqdm(examples, desc=\"formatting..\"):\n",
    "            f.write(json.dumps(format_example(json.loads(example))) + '\\n')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf40bb-8bb0-4fcb-bd14-9b414eb32426",
   "metadata": {},
   "source": [
    "## tokenize_dataset_rows.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d853b76a-3775-4cbc-b8d6-dd3157cc844a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T02:03:30.555969Z",
     "iopub.status.busy": "2023-04-08T02:03:30.555551Z",
     "iopub.status.idle": "2023-04-08T02:03:33.863590Z",
     "shell.execute_reply": "2023-04-08T02:03:33.863064Z",
     "shell.execute_reply.started": "2023-04-08T02:03:30.555936Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to /root/.cache/huggingface/datasets/generator/default-5161fd2f24be51ae/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "\n",
      "  0%|          | 0/186 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 186/186 [00:00<00:00, 1445.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to /root/.cache/huggingface/datasets/generator/default-5161fd2f24be51ae/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/186 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "\n",
    "\n",
    "def preprocess(tokenizer, config, example, max_seq_length):\n",
    "    prompt = example[\"context\"]\n",
    "    target = example[\"target\"]\n",
    "    prompt_ids = tokenizer.encode(prompt, max_length=max_seq_length, truncation=True,return_attention_mask=False,\n",
    "                add_special_tokens=False)\n",
    "    target_ids = tokenizer.encode(\n",
    "        target,\n",
    "        max_length=max_seq_length,\n",
    "        truncation=True,\n",
    "        return_attention_mask=False,\n",
    "        add_special_tokens=False)\n",
    "    input_ids = prompt_ids + [150001, 150004] + target_ids + [150005]\n",
    "    return {\"input_ids\": input_ids, \"seq_len\": len(prompt_ids)}\n",
    "\n",
    "\n",
    "def read_jsonl(path, max_seq_length, skip_overlength=False):\n",
    "    model_name = \"/openbayes/input/input1\"\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        model_name, trust_remote_code=True)\n",
    "    config = transformers.AutoConfig.from_pretrained(\n",
    "        model_name, trust_remote_code=True, device_map='auto')\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            example = json.loads(line)\n",
    "            feature = preprocess(tokenizer, config, example, max_seq_length)\n",
    "            if skip_overlength and len(feature[\"input_ids\"]) > max_seq_length:\n",
    "                continue\n",
    "            feature[\"input_ids\"] = feature[\"input_ids\"][:max_seq_length]\n",
    "            yield feature\n",
    "\n",
    "\n",
    "def main():\n",
    "    dataset = datasets.Dataset.from_generator(\n",
    "        lambda: read_jsonl(\"/output/train.jsonl\", 384, False)\n",
    "    )\n",
    "    dataset.save_to_disk(\"/output/train\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc6e27-1e1f-4bd8-9007-03bcaa66cfef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622a47ea-3edb-47b6-acb7-676eaeece34a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 训练前推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cbc632-542f-42e6-8b08-1ba36135b5e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T06:18:41.229529Z",
     "iopub.status.busy": "2023-04-07T06:18:41.228953Z",
     "iopub.status.idle": "2023-04-07T06:18:56.948182Z",
     "shell.execute_reply": "2023-04-07T06:18:56.947642Z",
     "shell.execute_reply.started": "2023-04-07T06:18:41.229488Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.111.0.1'), PosixPath('443'), PosixPath('tcp')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//alchemist-experience'), PosixPath('7890'), PosixPath('http')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('localhost,127.0.0.1,openbayes-server-svc,openbayes-storage-server-svc,10.0.0.0/8')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('phodal/jobs/c0bno6hguvkz')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/output/.torch')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//openbayes-server-svc/api/users/phodal/jobs/c0bno6hguvkz'), PosixPath('http')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('home/5d3115f4-9462-4893-9b8b-c30197fa15ad')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223a35d4ef81467999945a6d538ed711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "    def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "\n",
    "\n",
    "model = AutoModel.from_pretrained(\"/openbayes/input/input1\", load_in_8bit=True, trust_remote_code=True, device_map='auto')\n",
    "model.supports_gradient_checkpointing = True\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf75c23f-505a-40e8-aacc-4c6629d22214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T06:19:50.434271Z",
     "iopub.status.busy": "2023-04-07T06:19:50.433886Z",
     "iopub.status.idle": "2023-04-07T06:19:51.512812Z",
     "shell.execute_reply": "2023-04-07T06:19:51.511932Z",
     "shell.execute_reply.started": "2023-04-07T06:19:50.434232Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/openbayes/input/input1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ec68f27-f503-4295-b91d-3043230ed1a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T06:19:41.020148Z",
     "iopub.status.busy": "2023-04-07T06:19:41.019505Z",
     "iopub.status.idle": "2023-04-07T06:19:41.025152Z",
     "shell.execute_reply": "2023-04-07T06:19:41.024412Z",
     "shell.execute_reply.started": "2023-04-07T06:19:41.020111Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: create userstory tasks \\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    return {\"context\": context, \"target\": target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b63873-623b-4b7b-96af-0327583c383e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/openbayes/input/input0/datasets/userstory_map.jsonl\") as f:\n",
    "    examples = list(f)\n",
    "\n",
    "with torch.no_grad():\n",
    "    idx = 0\n",
    "    for example in examples[:5]:\n",
    "        item = json.loads(example)\n",
    "        feature = format_example(item)\n",
    "        input_text = feature['context']\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        inputs = model.prepare_inputs_for_generation(input_ids)\n",
    "        for k,v in inputs.items():\n",
    "            if v is not None:\n",
    "                inputs[k] = v.to(\"cuda\")\n",
    "        outputs = model.generate(**inputs, max_length=512, eos_token_id=tokenizer.eop_token_id)\n",
    "        out = outputs[0].tolist()[input_ids.size()[-1]:]\n",
    "        answer = tokenizer.decode(out)\n",
    "        item['infer_answer'] = answer\n",
    "        print(input_text)\n",
    "        print(answer)\n",
    "        print(f\"### {idx+1}.Answer:\\n\", item.get('output'), '\\n\\n')\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b5290-4037-4307-994a-f18e4dd8cede",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec408aa-4621-42a5-9ff7-81da8cf284f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T02:04:01.386906Z",
     "iopub.status.busy": "2023-04-08T02:04:01.386682Z",
     "iopub.status.idle": "2023-04-08T03:28:10.880357Z",
     "shell.execute_reply": "2023-04-08T03:28:10.879129Z",
     "shell.execute_reply.started": "2023-04-08T02:04:01.386889Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from transformers.integrations import TensorBoardCallback\n",
      "from torch.utils.tensorboard import SummaryWriter\n",
      "from transformers import TrainingArguments\n",
      "from transformers import Trainer, HfArgumentParser\n",
      "from transformers import AutoTokenizer, AutoModel\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from peft import get_peft_model, LoraConfig, TaskType\n",
      "from dataclasses import dataclass, field\n",
      "import datasets\n",
      "import os\n",
      "\n",
      "\n",
      "tokenizer = AutoTokenizer.from_pretrained(\"/openbayes/input/input1\", trust_remote_code=True)\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class FinetuneArguments:\n",
      "    dataset_path: str = field(default=\"data/alpaca\")\n",
      "    model_path: str = field(default=\"output\")\n",
      "    lora_rank: int = field(default=8)\n",
      "\n",
      "\n",
      "class CastOutputToFloat(nn.Sequential):\n",
      "    def forward(self, x):\n",
      "        return super().forward(x).to(torch.float32)\n",
      "\n",
      "\n",
      "def data_collator(features: list) -> dict:\n",
      "    len_ids = [len(feature[\"input_ids\"]) for feature in features]\n",
      "    longest = max(len_ids)\n",
      "    input_ids = []\n",
      "    labels_list = []\n",
      "    for ids_l, feature in sorted(zip(len_ids, features), key=lambda x: -x[0]):\n",
      "        ids = feature[\"input_ids\"]\n",
      "        seq_len = feature[\"seq_len\"]\n",
      "        labels = (\n",
      "            [-100] * (seq_len - 1) + ids[(seq_len - 1) :] + [-100] * (longest - ids_l)\n",
      "        )\n",
      "        ids = ids + [tokenizer.pad_token_id] * (longest - ids_l)\n",
      "        _ids = torch.LongTensor(ids)\n",
      "        labels_list.append(torch.LongTensor(labels))\n",
      "        input_ids.append(_ids)\n",
      "    input_ids = torch.stack(input_ids)\n",
      "    labels = torch.stack(labels_list)\n",
      "    return {\n",
      "        \"input_ids\": input_ids,\n",
      "        \"labels\": labels,\n",
      "    }\n",
      "\n",
      "\n",
      "class ModifiedTrainer(Trainer):\n",
      "    def compute_loss(self, model, inputs, return_outputs=False):\n",
      "        return model(\n",
      "            input_ids=inputs[\"input_ids\"],\n",
      "            labels=inputs[\"labels\"],\n",
      "        ).loss\n",
      "\n",
      "    def save_model(self, output_dir=None, _internal_call=False):\n",
      "        from transformers.trainer import TRAINING_ARGS_NAME\n",
      "\n",
      "        os.makedirs(output_dir, exist_ok=True)\n",
      "        torch.save(self.args, os.path.join(output_dir, TRAINING_ARGS_NAME))\n",
      "        saved_params = {\n",
      "            k: v.to(\"cpu\") for k, v in self.model.named_parameters() if v.requires_grad\n",
      "        }\n",
      "        torch.save(saved_params, os.path.join(output_dir, \"adapter_model.bin\"))\n",
      "\n",
      "\n",
      "def main():\n",
      "    writer = SummaryWriter()\n",
      "    finetune_args, training_args = HfArgumentParser(\n",
      "        (FinetuneArguments, TrainingArguments)\n",
      "    ).parse_args_into_dataclasses()\n",
      "\n",
      "    # init model\n",
      "    model = AutoModel.from_pretrained(\n",
      "        \"/openbayes/input/input1\", load_in_8bit=True, trust_remote_code=True, device_map=\"auto\"\n",
      "    )\n",
      "    model.gradient_checkpointing_enable()\n",
      "    model.enable_input_require_grads()\n",
      "    model.is_parallelizable = True\n",
      "    model.model_parallel = True\n",
      "    model.lm_head = CastOutputToFloat(model.lm_head)\n",
      "    model.config.use_cache = (\n",
      "        False  # silence the warnings. Please re-enable for inference!\n",
      "    )\n",
      "\n",
      "    # setup peft\n",
      "    peft_config = LoraConfig(\n",
      "        task_type=TaskType.CAUSAL_LM,\n",
      "        inference_mode=False,\n",
      "        r=finetune_args.lora_rank,\n",
      "        lora_alpha=32,\n",
      "        lora_dropout=0.1,\n",
      "    )\n",
      "    model = get_peft_model(model, peft_config)\n",
      "\n",
      "    # load dataset\n",
      "    dataset = datasets.load_from_disk(finetune_args.dataset_path)\n",
      "    print(f\"\\n{len(dataset)=}\\n\")\n",
      "\n",
      "    # start train\n",
      "    trainer = ModifiedTrainer(\n",
      "        model=model,\n",
      "        train_dataset=dataset,\n",
      "        args=training_args,\n",
      "        callbacks=[TensorBoardCallback(writer)],\n",
      "        data_collator=data_collator,\n",
      "    )\n",
      "    trainer.train()\n",
      "    writer.close()\n",
      "    # save model\n",
      "    model.save_pretrained(training_args.output_dir)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('home/e8fe329e-82d3-48a8-84b9-cd59cfd66f31')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.111.0.1'), PosixPath('tcp'), PosixPath('443')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('7890'), PosixPath('//alchemist-experience'), PosixPath('http')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('localhost,127.0.0.1,openbayes-server-svc,openbayes-storage-server-svc,10.0.0.0/8')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('phodal/jobs/c0bno6hguvkz')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/output/.torch')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//openbayes-server-svc/api/users/phodal/jobs/c0bno6hguvkz'), PosixPath('http')}\n",
      "  warn(msg)\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:08<00:00,  1.02s/it]\n",
      "\n",
      "len(dataset)=186\n",
      "\n",
      "You are adding a <class 'transformers.integrations.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "/usr/local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 1.4498, 'learning_rate': 9.843333333333333e-05, 'epoch': 1.61}         \n",
      "{'loss': 0.8616, 'learning_rate': 9.676666666666667e-05, 'epoch': 3.23}         \n",
      "{'loss': 0.6794, 'learning_rate': 9.51e-05, 'epoch': 4.84}                      \n",
      "{'loss': 0.5775, 'learning_rate': 9.343333333333335e-05, 'epoch': 6.45}         \n",
      "{'loss': 0.4772, 'learning_rate': 9.176666666666667e-05, 'epoch': 8.06}         \n",
      "{'loss': 0.3866, 'learning_rate': 9.010000000000001e-05, 'epoch': 9.68}         \n",
      "{'loss': 0.3174, 'learning_rate': 8.843333333333333e-05, 'epoch': 11.29}        \n",
      "{'loss': 0.2627, 'learning_rate': 8.676666666666667e-05, 'epoch': 12.9}         \n",
      "{'loss': 0.2042, 'learning_rate': 8.510000000000001e-05, 'epoch': 14.52}        \n",
      "{'loss': 0.1697, 'learning_rate': 8.343333333333335e-05, 'epoch': 16.13}        \n",
      "{'loss': 0.1304, 'learning_rate': 8.176666666666667e-05, 'epoch': 17.74}        \n",
      "{'loss': 0.11, 'learning_rate': 8.010000000000001e-05, 'epoch': 19.35}          \n",
      "{'loss': 0.093, 'learning_rate': 7.843333333333333e-05, 'epoch': 20.97}         \n",
      "{'loss': 0.0727, 'learning_rate': 7.676666666666667e-05, 'epoch': 22.58}        \n",
      "{'loss': 0.0665, 'learning_rate': 7.510000000000001e-05, 'epoch': 24.19}        \n",
      "{'loss': 0.0539, 'learning_rate': 7.343333333333333e-05, 'epoch': 25.81}        \n",
      "{'loss': 0.048, 'learning_rate': 7.176666666666667e-05, 'epoch': 27.42}         \n",
      "{'loss': 0.0384, 'learning_rate': 7.01e-05, 'epoch': 29.03}                     \n",
      "{'loss': 0.0334, 'learning_rate': 6.843333333333333e-05, 'epoch': 30.65}        \n",
      "{'loss': 0.0314, 'learning_rate': 6.676666666666667e-05, 'epoch': 32.26}        \n",
      " 33%|█████████████                          | 1000/3000 [27:56<57:11,  1.72s/it]/usr/local/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 0.0277, 'learning_rate': 6.510000000000001e-05, 'epoch': 33.87}        \n",
      "{'loss': 0.0252, 'learning_rate': 6.343333333333333e-05, 'epoch': 35.48}        \n",
      "{'loss': 0.0225, 'learning_rate': 6.176666666666667e-05, 'epoch': 37.1}         \n",
      "{'loss': 0.0181, 'learning_rate': 6.0100000000000004e-05, 'epoch': 38.71}       \n",
      "{'loss': 0.0136, 'learning_rate': 5.843333333333334e-05, 'epoch': 40.32}        \n",
      "{'loss': 0.0106, 'learning_rate': 5.6766666666666666e-05, 'epoch': 41.94}       \n",
      "{'loss': 0.0086, 'learning_rate': 5.5100000000000004e-05, 'epoch': 43.55}       \n",
      "{'loss': 0.0078, 'learning_rate': 5.3433333333333336e-05, 'epoch': 45.16}       \n",
      "{'loss': 0.0067, 'learning_rate': 5.1766666666666674e-05, 'epoch': 46.77}       \n",
      "{'loss': 0.0062, 'learning_rate': 5.0100000000000005e-05, 'epoch': 48.39}       \n",
      "{'loss': 0.0058, 'learning_rate': 4.8433333333333336e-05, 'epoch': 50.0}        \n",
      "{'loss': 0.0054, 'learning_rate': 4.676666666666667e-05, 'epoch': 51.61}        \n",
      "{'loss': 0.0051, 'learning_rate': 4.5100000000000005e-05, 'epoch': 53.23}       \n",
      "{'loss': 0.0048, 'learning_rate': 4.3433333333333336e-05, 'epoch': 54.84}       \n",
      "{'loss': 0.0045, 'learning_rate': 4.176666666666667e-05, 'epoch': 56.45}        \n",
      "{'loss': 0.0043, 'learning_rate': 4.0100000000000006e-05, 'epoch': 58.06}       \n",
      "{'loss': 0.004, 'learning_rate': 3.843333333333334e-05, 'epoch': 59.68}         \n",
      "{'loss': 0.004, 'learning_rate': 3.676666666666667e-05, 'epoch': 61.29}         \n",
      "{'loss': 0.0037, 'learning_rate': 3.51e-05, 'epoch': 62.9}                      \n",
      "{'loss': 0.0036, 'learning_rate': 3.343333333333333e-05, 'epoch': 64.52}        \n",
      " 67%|██████████████████████████             | 2000/3000 [55:55<36:09,  2.17s/it]/usr/local/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 0.0036, 'learning_rate': 3.176666666666667e-05, 'epoch': 66.13}        \n",
      "{'loss': 0.0034, 'learning_rate': 3.01e-05, 'epoch': 67.74}                     \n",
      "{'loss': 0.0032, 'learning_rate': 2.8433333333333334e-05, 'epoch': 69.35}       \n",
      "{'loss': 0.0032, 'learning_rate': 2.676666666666667e-05, 'epoch': 70.97}        \n",
      "{'loss': 0.0031, 'learning_rate': 2.51e-05, 'epoch': 72.58}                     \n",
      "{'loss': 0.003, 'learning_rate': 2.3433333333333335e-05, 'epoch': 74.19}        \n",
      "{'loss': 0.0029, 'learning_rate': 2.176666666666667e-05, 'epoch': 75.81}        \n",
      "{'loss': 0.0028, 'learning_rate': 2.01e-05, 'epoch': 77.42}                     \n",
      "{'loss': 0.0028, 'learning_rate': 1.8433333333333332e-05, 'epoch': 79.03}       \n",
      "{'loss': 0.0027, 'learning_rate': 1.6766666666666667e-05, 'epoch': 80.65}       \n",
      "{'loss': 0.0027, 'learning_rate': 1.51e-05, 'epoch': 82.26}                     \n",
      "{'loss': 0.0026, 'learning_rate': 1.3433333333333334e-05, 'epoch': 83.87}       \n",
      "{'loss': 0.0025, 'learning_rate': 1.1766666666666667e-05, 'epoch': 85.48}       \n",
      "{'loss': 0.0025, 'learning_rate': 1.0100000000000002e-05, 'epoch': 87.1}        \n",
      "{'loss': 0.0025, 'learning_rate': 8.433333333333333e-06, 'epoch': 88.71}        \n",
      "{'loss': 0.0024, 'learning_rate': 6.766666666666667e-06, 'epoch': 90.32}        \n",
      "{'loss': 0.0024, 'learning_rate': 5.1e-06, 'epoch': 91.94}                      \n",
      "{'loss': 0.0025, 'learning_rate': 3.4333333333333336e-06, 'epoch': 93.55}       \n",
      "{'loss': 0.0024, 'learning_rate': 1.7666666666666668e-06, 'epoch': 95.16}       \n",
      "{'loss': 0.0024, 'learning_rate': 1.0000000000000001e-07, 'epoch': 96.77}       \n",
      "{'train_runtime': 5030.6521, 'train_samples_per_second': 3.578, 'train_steps_per_second': 0.596, 'train_loss': 0.10518931210041046, 'epoch': 96.77}\n",
      "100%|█████████████████████████████████████| 3000/3000 [1:23:50<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "!sed -i \"s/THUDM\\/chatglm-6b/\\/openbayes\\/input\\/input1/\" finetune.py\n",
    "!cat finetune.py\n",
    "!python finetune.py \\\n",
    "    --dataset_path /output/train \\\n",
    "    --lora_rank 8 \\\n",
    "    --per_device_train_batch_size 6 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --max_steps 3000 \\\n",
    "    --save_steps 1000 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --fp16 \\\n",
    "    --remove_unused_columns false \\\n",
    "    --logging_steps 50 \\\n",
    "    --output_dir /output/lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35a70e-3ff4-4313-80e6-2d73d2b148da",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练后推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37829bbb-299f-4fc7-b9d9-44ed9d5b339c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T03:29:05.597596Z",
     "iopub.status.busy": "2023-04-08T03:29:05.597169Z",
     "iopub.status.idle": "2023-04-08T03:29:16.464222Z",
     "shell.execute_reply": "2023-04-08T03:29:16.463494Z",
     "shell.execute_reply.started": "2023-04-08T03:29:05.597561Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbe557545a14df7a067c53f36914d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/usr/local/lib/python3.8/site-packages/peft/tuners/lora.py:191: UserWarning: fan_in_fan_out is set to True but the target module is not a Conv1D. Setting fan_in_fan_out to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "model = AutoModel.from_pretrained(\"/openbayes/input/input1\", trust_remote_code=True, device_map='auto')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/openbayes/input/input1\", trust_remote_code=True)\n",
    "\n",
    "peft_path = \"/output/lora/adapter_model.bin\"\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=True,\n",
    "    r=8,\n",
    "    lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "model.load_state_dict(torch.load(peft_path), strict=False)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad183f8c-1135-457d-9e80-60eb68c6c56e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 原样输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2e2d4c-8bf6-4f7f-baa5-3cf8cc4f242d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T03:30:21.602124Z",
     "iopub.status.busy": "2023-04-08T03:30:21.601948Z",
     "iopub.status.idle": "2023-04-08T03:30:40.633074Z",
     "shell.execute_reply": "2023-04-08T03:30:40.632208Z",
     "shell.execute_reply.started": "2023-04-08T03:30:21.602106Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: create userstory tasks \n",
      "Input:  Animation and Comics\n",
      "Answer: \n",
      "\n",
      "User Tasks:\n",
      "1. Browse and search for animations and comics\n",
      "2. View details of animations and comics\n",
      "3. Create an account\n",
      "4. Log in to the account\n",
      "5. Add animations and comics to favorites\n",
      "6. Download animations and comics\n",
      "7. Share animations and comics with friends\n",
      "8. Rate and review animations and comics\n",
      "9. Create and upload animations and comics\n",
      "10. Participate in online forums and discussions\n",
      "### 1.Answer:\n",
      " \n",
      "User Tasks:\n",
      "1. Browse and search for animations and comics\n",
      "2. View details of animations and comics\n",
      "3. Create an account\n",
      "4. Log in to the account\n",
      "5. Add animations and comics to favorites\n",
      "6. Download animations and comics\n",
      "7. Share animations and comics with friends\n",
      "8. Rate and review animations and comics\n",
      "9. Create and upload animations and comics\n",
      "10. Participate in online forums and discussions \n",
      "\n",
      "\n",
      "Instruction: create userstory tasks \n",
      "Input:  Business Services\n",
      "Answer: \n",
      "\n",
      "User Tasks:\n",
      "1. Log in to the Business Services application\n",
      "2. View available services\n",
      "3. Select a service\n",
      "4. Enter payment information\n",
      "5. Receive confirmation of service purchase\n",
      "6. View service history\n",
      "7. Update account information\n",
      "8. Contact customer service\n",
      "9. Log out of the application\n",
      "### 2.Answer:\n",
      " \n",
      "User Tasks:\n",
      "1. Log in to the Business Services application\n",
      "2. View available services\n",
      "3. Select a service\n",
      "4. Enter payment information\n",
      "5. Receive confirmation of service purchase\n",
      "6. View service history\n",
      "7. Update account information\n",
      "8. Contact customer service\n",
      "9. Log out of the application \n",
      "\n",
      "\n",
      "Instruction: create userstory tasks \n",
      "Input:  Furniture\n",
      "Answer: \n",
      "\n",
      "User Tasks:\n",
      "1. Browse furniture catalog\n",
      "2. Select furniture item\n",
      "3. View product details\n",
      "4. Add item to cart\n",
      "5. Checkout\n",
      "6. Enter payment information\n",
      "7. Confirm order\n",
      "8. Track order status\n",
      "9. Receive order\n",
      "10. Leave feedback\n",
      "### 3.Answer:\n",
      " \n",
      "User Tasks:\n",
      "1. Browse furniture catalog\n",
      "2. Select furniture item\n",
      "3. View product details\n",
      "4. Add item to cart\n",
      "5. Checkout\n",
      "6. Enter payment information\n",
      "7. Confirm order\n",
      "8. Track order status\n",
      "9. Receive order\n",
      "10. Leave feedback \n",
      "\n",
      "\n",
      "Instruction: create userstory tasks \n",
      "Input:  Gardening\n",
      "Answer: \n",
      "\n",
      "User Tasks:\n",
      "1. Research gardening techniques and tools\n",
      "2. Select plants and tools for gardening\n",
      "3. Purchase plants and tools\n",
      "4. Prepare soil for planting\n",
      "5. Plant and water plants\n",
      "6. Monitor plants for pests and diseases\n",
      "7. Prune and trim plants\n",
      "8. Harvest plants\n",
      "9. Compost plant waste\n",
      "10. Share gardening tips and experiences with other gardeners\n",
      "### 4.Answer:\n",
      " \n",
      "User Tasks:\n",
      "1. Research gardening techniques and tools\n",
      "2. Select plants and tools for gardening\n",
      "3. Purchase plants and tools\n",
      "4. Prepare soil for planting\n",
      "5. Plant and water plants\n",
      "6. Monitor plants for pests and diseases\n",
      "7. Prune and trim plants\n",
      "8. Harvest plants\n",
      "9. Compost plant waste\n",
      "10. Share gardening tips and experiences with other gardeners \n",
      "\n",
      "\n",
      "Instruction: create userstory tasks \n",
      "Input:  Home and Garden\n",
      "Answer: \n",
      "\n",
      "User Tasks:\n",
      "1. Browse home and garden products\n",
      "2. View product details\n",
      "3. Add products to cart\n",
      "4. Checkout and pay for products\n",
      "5. Track order status\n",
      "6. Receive order confirmation\n",
      "7. Leave product reviews\n",
      "8. Ask questions about products\n",
      "9. Contact customer service\n",
      "10. Manage account settings\n",
      "11. Receive product recommendations\n",
      "12. Save favorite products\n",
      "### 5.Answer:\n",
      " \n",
      "User Tasks:\n",
      "1. Browse home and garden products\n",
      "2. View product details\n",
      "3. Add products to cart\n",
      "4. Checkout and pay for products\n",
      "5. Track order status\n",
      "6. Receive order confirmation\n",
      "7. Leave product reviews\n",
      "8. Ask questions about products\n",
      "9. Contact customer service\n",
      "10. Manage account settings\n",
      "11. Receive product recommendations\n",
      "12. Save favorite products \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: create userstory tasks \\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    return {\"context\": context, \"target\": target}\n",
    "\n",
    "with open(\"/openbayes/input/input0/datasets/userstory_map.jsonl\") as f:\n",
    "    examples = list(f)\n",
    "\n",
    "with torch.no_grad():\n",
    "    idx = 0\n",
    "    for example in examples[:5]:\n",
    "        item = json.loads(example)\n",
    "        feature = format_example(item)\n",
    "        input_text = feature['context']\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        inputs = model.prepare_inputs_for_generation(input_ids)\n",
    "        for k,v in inputs.items():\n",
    "            if v is not None:\n",
    "                inputs[k] = v.to(\"cuda\")\n",
    "        outputs = model.generate(**inputs, max_length=512, eos_token_id=tokenizer.eop_token_id)\n",
    "        out = outputs[0].tolist()[input_ids.size()[-1]:]\n",
    "        answer = tokenizer.decode(out)\n",
    "        item['infer_answer'] = answer\n",
    "        print(input_text)\n",
    "        print(answer)\n",
    "        print(f\"### {idx+1}.Answer:\\n\", item.get('output'), '\\n\\n')\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8471d07-54fd-4d90-823e-1b84c9009294",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 任意Prompt推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14bf6699-8956-4b13-a265-2b0ab846b46e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T03:30:51.654113Z",
     "iopub.status.busy": "2023-04-08T03:30:51.653718Z",
     "iopub.status.idle": "2023-04-08T03:30:51.661100Z",
     "shell.execute_reply": "2023-04-08T03:30:51.660240Z",
     "shell.execute_reply.started": "2023-04-08T03:30:51.654079Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    inputs = model.prepare_inputs_for_generation(input_ids)\n",
    "    for k,v in inputs.items():\n",
    "        if v is not None:\n",
    "            inputs[k] = v.to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_length=512, eos_token_id=tokenizer.eop_token_id)\n",
    "    out = outputs[0].tolist()[input_ids.size()[-1]:]\n",
    "    answer = tokenizer.decode(out)\n",
    "\n",
    "    print(input_text)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7a02b2c-7e7f-47ce-a0a6-42c057c3517d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T03:30:53.894528Z",
     "iopub.status.busy": "2023-04-08T03:30:53.894167Z",
     "iopub.status.idle": "2023-04-08T03:30:56.448861Z",
     "shell.execute_reply": "2023-04-08T03:30:56.448036Z",
     "shell.execute_reply.started": "2023-04-08T03:30:53.894496Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: create userstory tasks \n",
      "Input: 淘宝\n",
      "Answer:\n",
      "\n",
      "User Tasks:\n",
      "1. Create an account\n",
      "2. Log in to the application\n",
      "3. View available products\n",
      "4. Select a product to view\n",
      "5. View product details\n",
      "6. Purchase a product\n",
      "7. Log out of the application\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Instruction: create userstory tasks \\nInput: 淘宝\\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97ee5148-a6b5-4388-bad8-a315f66a7fab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T03:31:07.644922Z",
     "iopub.status.busy": "2023-04-08T03:31:07.644688Z",
     "iopub.status.idle": "2023-04-08T03:31:17.814575Z",
     "shell.execute_reply": "2023-04-08T03:31:17.814001Z",
     "shell.execute_reply.started": "2023-04-08T03:31:07.644905Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: create userstory tasks \n",
      "Input: 电影网站\n",
      "Answer:\n",
      "\n",
      "User Tasks:\n",
      "1. Search for movies\n",
      "2. View movie details\n",
      "3. Add movies to favorites\n",
      "4. View movie ratings and reviews\n",
      "5. View movie schedules\n",
      "6. View movie ratings and reviews\n",
      "7. Share movies with friends\n",
      "8. View movie trailers\n",
      "9. View movie budgets\n",
      "10. View movie theaters near me\n",
      "11. View movie theaters list\n",
      "12. View movie theaters near location\n",
      "13. View movie tips and tricks\n",
      "14. View movie tutorials\n",
      "15. View movie trailers\n",
      "16. View movie trailers\n",
      "17. View movie trailers\n",
      "18. View movie trailers\n",
      "19. View movie trailers\n",
      "20. View movie trailers\n",
      "21. View movie trailers\n",
      "22. View movie trailers\n",
      "23. View movie trailers\n",
      "24. View movie trailers\n",
      "25. View movie trailers\n",
      "26. View movie trailers\n",
      "27. View movie trailers\n",
      "28. View movie trailers\n",
      "29. View movie trailers\n",
      "30. View movie trailers\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Instruction: create userstory tasks \\nInput: 电影网站\\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d575f044-e6df-4752-92bb-9e5a9b7bb2bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T03:31:25.867355Z",
     "iopub.status.busy": "2023-04-08T03:31:25.866894Z",
     "iopub.status.idle": "2023-04-08T03:31:32.472933Z",
     "shell.execute_reply": "2023-04-08T03:31:32.472405Z",
     "shell.execute_reply.started": "2023-04-08T03:31:25.867333Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: create userstory tasks \n",
      "Input: 团购网站\n",
      "Answer:\n",
      "\n",
      "User Tasks:\n",
      "1. Search for团购商品\n",
      "2. View团购信息\n",
      "3. Add团购商品 to cart\n",
      "4. Make payment\n",
      "5. Receive团购商品\n",
      "6. View团购商品\n",
      "7. Share团购商品\n",
      "8. Check out团购商品\n",
      "9. Receive团购 result\n",
      "10. View团购信息\n",
      "11. Make团购信息\n",
      "12. Check团购信息\n",
      "13. Check out团购信息\n",
      "14. Make payment团购\n",
      "15. View团购信息\n",
      "16. View团购商品\n",
      "17. View团购评论\n",
      "18. Leave团购评论\n",
      "19. Get团购 feedback\n",
      "20. Get团购 update\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Instruction: create userstory tasks \\nInput: 团购网站\\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcf83312-6949-4284-ad75-50ad083de35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T03:31:43.360085Z",
     "iopub.status.busy": "2023-04-08T03:31:43.359666Z",
     "iopub.status.idle": "2023-04-08T03:31:47.588396Z",
     "shell.execute_reply": "2023-04-08T03:31:47.587879Z",
     "shell.execute_reply.started": "2023-04-08T03:31:43.360051Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: create userstory tasks \n",
      "Input: 博客网站\n",
      "Answer:\n",
      "\n",
      "User Tasks:\n",
      "1. Search for博客网站\n",
      "2. View博客网站\n",
      "3. Follow other users\n",
      "4. Create and save的博客 posts\n",
      "5. View博客 post\n",
      "6. Share博客 post\n",
      "7. Write and save blog posts\n",
      "8. View blog posts\n",
      "9. Edit blog posts\n",
      "10. Follow other bloggers\n",
      "11. View bloggers' blog posts\n",
      "12. View blog posts by other bloggers\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Instruction: create userstory tasks \\nInput: 博客网站\\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ef11023-c3a7-4ae4-81d7-43eaed264065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T03:31:55.227645Z",
     "iopub.status.busy": "2023-04-08T03:31:55.227415Z",
     "iopub.status.idle": "2023-04-08T03:31:59.225141Z",
     "shell.execute_reply": "2023-04-08T03:31:59.224614Z",
     "shell.execute_reply.started": "2023-04-08T03:31:55.227628Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: create userstory tasks \n",
      "Input: 京西商城\n",
      "Answer:\n",
      "\n",
      "User Tasks:\n",
      "1. Search for products by category\n",
      "2. View product details\n",
      "3. Add products to cart\n",
      "4. Checkout and pay for products\n",
      "5. Receive order confirmation\n",
      "6. Track order status\n",
      "7. View order history\n",
      "8. Leave feedback on product quality, service, or other issues\n",
      "9. Contact customer service for assistance\n",
      "10. Read product descriptions and reviews\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Instruction: create userstory tasks \\nInput: 京西商城\\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61e2c8-b5b7-4949-bf27-926fa485b802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate(\"Instruction: create userstory tasks \\nInput: 大信聊天\\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554b18da-0b1a-4ea1-b4c0-f5a7e0802f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
