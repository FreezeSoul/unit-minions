{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39616240-0e59-45d8-88c1-35b87e340324",
   "metadata": {},
   "source": [
    "# Alpaca Lora Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff1154-f001-4310-af1e-97feb6a1f298",
   "metadata": {},
   "source": [
    "详细思路见：[https://github.com/unit-mesh/unit-minions](https://github.com/unit-mesh/unit-minions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc0878-0e40-4632-8162-7d2227809657",
   "metadata": {},
   "source": [
    "## Setup LFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a6f80-0723-40ee-812f-8164e6b038a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt install git-lfs\n",
    "# check install\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdbf030",
   "metadata": {},
   "source": [
    "## Clone to Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434bee3a-5913-48f4-86e3-16a3e42a2a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T00:56:12.993957Z",
     "iopub.status.busy": "2023-04-08T00:56:12.993528Z",
     "iopub.status.idle": "2023-04-08T01:01:14.222691Z",
     "shell.execute_reply": "2023-04-08T01:01:14.221943Z",
     "shell.execute_reply.started": "2023-04-08T00:56:12.993911Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llama-7b-hf'...\n",
      "remote: Enumerating objects: 91, done.\u001b[K\n",
      "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
      "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
      "remote: Total 91 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (91/91), done.\n",
      "Filtering content: 100% (34/34), 12.55 GiB | 42.81 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/decapoda-research/llama-7b-hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278f1e6",
   "metadata": {},
   "source": [
    "# Traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b18a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/tloen/alpaca-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b5f942-504e-492f-a25b-c6795a538ab2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T01:06:50.688911Z",
     "iopub.status.busy": "2023-04-08T01:06:50.688540Z",
     "iopub.status.idle": "2023-04-08T01:07:18.482481Z",
     "shell.execute_reply": "2023-04-08T01:07:18.481393Z",
     "shell.execute_reply.started": "2023-04-08T01:06:50.688876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'alpaca-lora'\n",
      "/output/alpaca-lora\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting git+https://github.com/huggingface/transformers.git@c612628045822f909020f7eb6784c79700813eda (from -r requirements.txt (line 10))\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision c612628045822f909020f7eb6784c79700813eda) to /tmp/pip-req-build-c1w6a_2v\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-c1w6a_2v\n",
      "  Running command git rev-parse -q --verify 'sha^c612628045822f909020f7eb6784c79700813eda'\n",
      "  Running command git fetch -q https://github.com/huggingface/transformers.git c612628045822f909020f7eb6784c79700813eda\n",
      "  Running command git checkout -q c612628045822f909020f7eb6784c79700813eda\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit c612628045822f909020f7eb6784c79700813eda\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting git+https://github.com/huggingface/peft.git@e536616888d51b453ed354a6f1e243fecb02ea08 (from -r requirements.txt (line 11))\n",
      "  Cloning https://github.com/huggingface/peft.git (to revision e536616888d51b453ed354a6f1e243fecb02ea08) to /tmp/pip-req-build-brnqsgmv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-brnqsgmv\n",
      "  Running command git rev-parse -q --verify 'sha^e536616888d51b453ed354a6f1e243fecb02ea08'\n",
      "  Running command git fetch -q https://github.com/huggingface/peft.git e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Running command git checkout -q e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Resolved https://github.com/huggingface/peft.git to commit e536616888d51b453ed354a6f1e243fecb02ea08\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (0.37.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: loralib in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: black in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (23.3.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (2.11.0)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.97 in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.1.97)\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (3.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 2)) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 2)) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 2)) (1.13.1+cu117)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 2)) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/site-packages (from black->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.8/site-packages (from black->-r requirements.txt (line 6)) (8.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.8/site-packages (from black->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/site-packages (from black->-r requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.8/site-packages (from black->-r requirements.txt (line 6)) (0.11.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/site-packages (from black->-r requirements.txt (line 6)) (2.6.2)\n",
      "Requirement already satisfied: ipython>=7.8.0 in /usr/local/lib/python3.8/site-packages (from black->-r requirements.txt (line 6)) (8.8.0)\n",
      "Requirement already satisfied: tokenize-rt>=3.2.0 in /usr/local/lib/python3.8/site-packages (from black->-r requirements.txt (line 6)) (5.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (0.13.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (2.28.1)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (2023.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (1.5.2)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 8)) (0.70.14)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from fire->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/site-packages (from fire->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/site-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 10)) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/site-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 10)) (2023.3.23)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from transformers==4.28.0.dev0->-r requirements.txt (line 10)) (3.11.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (3.6.2)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (0.20.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (3.1.2)\n",
      "Requirement already satisfied: gradio-client>=0.0.5 in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (0.0.8)\n",
      "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (4.2.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (2.2.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (11.0.1)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (0.95.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (9.4.0)\n",
      "Requirement already satisfied: aiofiles in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (23.1.0)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (0.25.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (0.23.3)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (3.8.9)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (1.10.7)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (0.3.3)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (0.3.0)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (0.0.6)\n",
      "Requirement already satisfied: markupsafe in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (2.1.1)\n",
      "Requirement already satisfied: semantic-version in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 13)) (2.10.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.8/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 13)) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 13)) (4.17.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 13)) (0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 8)) (1.8.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (3.0.36)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (5.8.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (5.1.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.6.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/site-packages (from ipython>=7.8.0->black->-r requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.8/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 13)) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas->datasets->-r requirements.txt (line 8)) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/site-packages (from pandas->datasets->-r requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 8)) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 8)) (1.26.13)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.8/site-packages (from fastapi->gradio->-r requirements.txt (line 13)) (0.26.1)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.8/site-packages (from httpx->gradio->-r requirements.txt (line 13)) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.8/site-packages (from httpx->gradio->-r requirements.txt (line 13)) (0.16.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/site-packages (from httpx->gradio->-r requirements.txt (line 13)) (1.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (0.11.0)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.8/site-packages (from uvicorn->gradio->-r requirements.txt (line 13)) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.8/site-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 13)) (3.6.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.8.3)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 13)) (5.10.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 13)) (0.19.3)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /usr/local/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 13)) (1.3.10)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.8/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 13)) (1.0.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.2.5)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.8/site-packages (from stack-data->ipython>=7.8.0->black->-r requirements.txt (line 6)) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.8/site-packages (from stack-data->ipython>=7.8.0->black->-r requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.8/site-packages (from stack-data->ipython>=7.8.0->black->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 13)) (3.11.0)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=41645 sha256=cd10e4b989942589f1c4e3acafc945791d322d5f10b0c569d72ffa2a4c3310b0\n",
      "  Stored in directory: /root/.cache/pip/wheels/da/70/31/9924c81a28479a21d715f7bfae13723f624e706d93b97c4b78\n",
      "Successfully built peft\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.3.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd alpaca-lora && !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cce5ab-77d9-40b0-9fa4-61f3de1381f2",
   "metadata": {},
   "source": [
    "## Training in Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7a120f-acef-4e77-822c-d298f4920304",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normal Traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "712b1e50-fbb6-4ff1-bf09-62466be77e60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T01:36:51.423265Z",
     "iopub.status.busy": "2023-04-08T01:36:51.422970Z",
     "iopub.status.idle": "2023-04-08T02:28:43.051922Z",
     "shell.execute_reply": "2023-04-08T02:28:43.051319Z",
     "shell.execute_reply.started": "2023-04-08T01:36:51.423247Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib64'), PosixPath('/usr/local/nvidia/lib')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('home/81fa1036-fb46-4b3c-9dd5-96e8dbc216d2')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('443'), PosixPath('//10.111.0.1'), PosixPath('tcp')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//alchemist-experience'), PosixPath('http'), PosixPath('7890')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('localhost,127.0.0.1,openbayes-server-svc,openbayes-storage-server-svc,10.0.0.0/8')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('phodal/jobs/fjkeasq4qqzr')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/output/.torch')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//openbayes-server-svc/api/users/phodal/jobs/fjkeasq4qqzr')}\n",
      "  warn(msg)\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "Training Alpaca-LoRA model with params:\n",
      "base_model: ../llama-7b-hf\n",
      "data_path: ../sql-train-8k.jsonl\n",
      "output_dir: ./lora-alpaca\n",
      "batch_size: 128\n",
      "micro_batch_size: 4\n",
      "num_epochs: 3\n",
      "learning_rate: 0.0003\n",
      "cutoff_len: 256\n",
      "val_set_size: 2000\n",
      "lora_r: 8\n",
      "lora_alpha: 16\n",
      "lora_dropout: 0.05\n",
      "lora_target_modules: ['q_proj', 'v_proj']\n",
      "train_on_inputs: True\n",
      "group_by_length: False\n",
      "wandb_project: \n",
      "wandb_run_name: \n",
      "wandb_watch: \n",
      "wandb_log_model: \n",
      "resume_from_checkpoint: False\n",
      "prompt template: alpaca\n",
      "\n",
      "Loading checkpoint shards: 100%|████████████████| 33/33 [00:06<00:00,  4.73it/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-42de950d11b8db8a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n",
      "Downloading data files: 100%|███████████████████| 1/1 [00:00<00:00, 1614.44it/s]\n",
      "Extracting data files: 100%|████████████████████| 1/1 [00:00<00:00, 1657.83it/s]\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-42de950d11b8db8a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 883.01it/s]\n",
      "trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199\n",
      "{'loss': 3.3701, 'learning_rate': 2.9999999999999997e-05, 'epoch': 0.21}        \n",
      "{'loss': 3.2419, 'learning_rate': 5.9999999999999995e-05, 'epoch': 0.43}        \n",
      "{'loss': 2.8466, 'learning_rate': 8.999999999999999e-05, 'epoch': 0.64}         \n",
      "{'loss': 2.0627, 'learning_rate': 0.00011999999999999999, 'epoch': 0.85}        \n",
      "{'loss': 1.3579, 'learning_rate': 0.00015, 'epoch': 1.07}                       \n",
      "{'loss': 1.0043, 'learning_rate': 0.00017999999999999998, 'epoch': 1.28}        \n",
      "{'loss': 0.7123, 'learning_rate': 0.00020999999999999998, 'epoch': 1.49}        \n",
      "{'loss': 0.688, 'learning_rate': 0.00023999999999999998, 'epoch': 1.71}         \n",
      "{'loss': 0.661, 'learning_rate': 0.00027, 'epoch': 1.92}                        \n",
      "{'loss': 0.6363, 'learning_rate': 0.0003, 'epoch': 2.13}                        \n",
      "{'loss': 0.6173, 'learning_rate': 0.00022105263157894733, 'epoch': 2.35}        \n",
      "{'loss': 0.6125, 'learning_rate': 0.0001421052631578947, 'epoch': 2.56}         \n",
      "{'loss': 0.6129, 'learning_rate': 6.315789473684209e-05, 'epoch': 2.77}         \n",
      "{'train_runtime': 3095.5052, 'train_samples_per_second': 5.816, 'train_steps_per_second': 0.045, 'train_loss': 1.370294401611107, 'epoch': 2.94}\n",
      "100%|█████████████████████████████████████████| 138/138 [51:35<00:00, 22.43s/it]\n",
      "\n",
      " If there's a warning about missing keys above, please disregard :)\n"
     ]
    }
   ],
   "source": [
    "!cd alpaca-lora && python finetune.py \\\n",
    "    --base_model '../llama-7b-hf' \\\n",
    "    --data_path '../sql-train-8k.jsonl' \\\n",
    "    --output_dir './lora-alpaca'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58975bf9-4e94-4ace-b97c-47dada25a931",
   "metadata": {},
   "source": [
    "# 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66bef68-2894-4e2e-ae57-78e5ba485e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T02:29:55.924170Z",
     "iopub.status.busy": "2023-04-08T02:29:55.923527Z",
     "iopub.status.idle": "2023-04-08T02:30:19.994234Z",
     "shell.execute_reply": "2023-04-08T02:30:19.993126Z",
     "shell.execute_reply.started": "2023-04-08T02:29:55.924137Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//10.111.0.1'), PosixPath('443'), PosixPath('tcp')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//alchemist-experience'), PosixPath('7890')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('localhost,127.0.0.1,openbayes-server-svc,openbayes-storage-server-svc,10.0.0.0/8')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('phodal/jobs/fjkeasq4qqzr')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/output/.torch')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('//openbayes-server-svc/api/users/phodal/jobs/fjkeasq4qqzr')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('home/81fa1036-fb46-4b3c-9dd5-96e8dbc216d2')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7e4db3bd4143a08f3b0ba157240951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "import transformers\n",
    "import gradio as gr\n",
    "\n",
    "assert (\n",
    "    \"LlamaTokenizer\" in transformers._import_structure[\"models.llama\"]\n",
    "), \"LLaMA is now in HuggingFace's main branch.\\nPlease reinstall it: pip uninstall transformers && pip install git+https://github.com/huggingface/transformers.git\"\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"./llama-7b-hf\")\n",
    "\n",
    "BASE_MODEL = \"./llama-7b-hf\"\n",
    "LORA_WEIGHTS = \"./alpaca-lora/lora-alpaca\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "try:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        load_in_8bit=False,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model, LORA_WEIGHTS, torch_dtype=torch.float16, force_download=True\n",
    "    )\n",
    "elif device == \"mps\":\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        device_map={\"\": device},\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model,\n",
    "        LORA_WEIGHTS,\n",
    "        device_map={\"\": device},\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "else:\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        BASE_MODEL, device_map={\"\": device}, low_cpu_mem_usage=True\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model,\n",
    "        LORA_WEIGHTS,\n",
    "        device_map={\"\": device},\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_prompt(instruction, input=None):\n",
    "    if input:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "### Input:\n",
    "{input}\n",
    "### Response:\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "### Response:\"\"\"\n",
    "\n",
    "if device != \"cpu\":\n",
    "    model.half()\n",
    "model.eval()\n",
    "if torch.__version__ >= \"2\":\n",
    "    model = torch.compile(model)\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    instruction,\n",
    "    input=None,\n",
    "    temperature=0.1,\n",
    "    top_p=0.75,\n",
    "    top_k=40,\n",
    "    num_beams=4,\n",
    "    max_new_tokens=128,\n",
    "    **kwargs,\n",
    "):\n",
    "    prompt = generate_prompt(instruction, input)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        num_beams=num_beams,\n",
    "        **kwargs,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "    s = generation_output.sequences[0]\n",
    "    output = tokenizer.decode(s)\n",
    "    print(output.split(\"### Response:\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6417ba24-7c62-46b6-9b15-6c6aedda2577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T01:33:45.540076Z",
     "iopub.status.busy": "2023-04-08T01:33:45.539888Z",
     "iopub.status.idle": "2023-04-08T01:33:52.492379Z",
     "shell.execute_reply": "2023-04-08T01:33:52.491845Z",
     "shell.execute_reply.started": "2023-04-08T01:33:45.540053Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT MOST BEAUTIFUL PERSON\n",
      "SELECT 年龄\n",
      "SELECT Hand Guard System FROM table WHERE Gas Piston Commando\n"
     ]
    }
   ],
   "source": [
    "## 4K\n",
    "\n",
    "evaluate(\"text to sql\", \"谁是最美丽的人\", 0.1, 0.75, 40, 4, 512)\n",
    "evaluate(\"text to sql\", \"小明今年几岁\", 0.1, 0.75, 40, 4, 512)\n",
    "evaluate(\"text to sql\", \"What hand guard system is used with a gas piston commando?\", 0.1, 0.75, 40, 4, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e20bb9-2695-4f27-9d8e-a68273ea449c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-08T02:30:19.996135Z",
     "iopub.status.busy": "2023-04-08T02:30:19.995589Z",
     "iopub.status.idle": "2023-04-08T02:30:24.525666Z",
     "shell.execute_reply": "2023-04-08T02:30:24.524651Z",
     "shell.execute_reply.started": "2023-04-08T02:30:19.996117Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT MOST BEAUTIFUL FROM table WHERE BEAUTIFUL = 最美丽的人\n",
      "SELECT MIN Year FROM table\n",
      "SELECT Hand guard system FROM table WHERE Gas piston = Commando\n"
     ]
    }
   ],
   "source": [
    "# 8k\n",
    "\n",
    "evaluate(\"text to sql\", \"谁是最美丽的人\", 0.1, 0.75, 40, 4, 512)\n",
    "evaluate(\"text to sql\", \"小明今年几岁\", 0.1, 0.75, 40, 4, 512)\n",
    "evaluate(\"text to sql\", \"What hand guard system is used with a gas piston commando?\", 0.1, 0.75, 40, 4, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5a3db-c6ab-46e1-a257-d195477e0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 56k\n",
    "\n",
    "evaluate(\"text to sql\", \"谁是最美丽的人\", 0.1, 0.75, 40, 4, 512)\n",
    "evaluate(\"text to sql\", \"小明今年几岁\", 0.1, 0.75, 40, 4, 512)\n",
    "evaluate(\"text to sql\", \"What hand guard system is used with a gas piston commando?\", 0.1, 0.75, 40, 4, 512)\n",
    "\n",
    "# SELECT Name FROM table WHERE 最美丽的人 = 谁是最美丽的人\n",
    "# SELECT Year FROM table WHERE Name = 小明今年几岁\n",
    "# SELECT Hand guard system FROM table WHERE Gas piston commando = yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
