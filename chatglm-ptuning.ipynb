{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "087b530f",
   "metadata": {},
   "source": [
    "# 前置动作\n",
    "1. 克隆https://github.com/unit-mesh/unit-minions项目\n",
    "2. 将userstory_detail_double_clean_cn.jsonl数据集放到input0或者修改下面的数据集路径\n",
    "3. 将ChatGLM-6b的模型文件准备到input2或者修改下面模型引用的路径。或者直接指定为THUDM/chatglm-6b\n",
    "4. 如果不是用的openbayes平台，记得修改下方的模型输出路径，并提前创建好路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a2748b-441a-4e87-94f3-26142b266014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T07:40:10.063778Z",
     "iopub.status.busy": "2023-04-09T07:40:10.063458Z",
     "iopub.status.idle": "2023-04-09T07:40:11.716573Z",
     "shell.execute_reply": "2023-04-09T07:40:11.715809Z",
     "shell.execute_reply.started": "2023-04-09T07:40:10.063751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ChatGLM-6B'...\n",
      "remote: Enumerating objects: 742, done.\u001b[K\n",
      "remote: Counting objects: 100% (452/452), done.\u001b[K\n",
      "remote: Compressing objects: 100% (212/212), done.\u001b[K\n",
      "remote: Total 742 (delta 282), reused 291 (delta 239), pack-reused 290\u001b[K\n",
      "Receiving objects: 100% (742/742), 5.68 MiB | 16.29 MiB/s, done.\n",
      "Resolving deltas: 100% (422/422), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/THUDM/ChatGLM-6B.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db69ab3-3859-49cf-8b4c-2421baeb8ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:59:49.314951Z",
     "iopub.status.busy": "2023-04-14T04:59:49.314543Z",
     "iopub.status.idle": "2023-04-14T04:59:49.319781Z",
     "shell.execute_reply": "2023-04-14T04:59:49.319183Z",
     "shell.execute_reply.started": "2023-04-14T04:59:49.314916Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/ChatGLM-6B\n"
     ]
    }
   ],
   "source": [
    "%cd ChatGLM-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab76059-443b-4718-b68d-450381e7f577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:59:51.713343Z",
     "iopub.status.busy": "2023-04-14T04:59:51.712453Z",
     "iopub.status.idle": "2023-04-14T04:59:52.553991Z",
     "shell.execute_reply": "2023-04-14T04:59:52.553421Z",
     "shell.execute_reply.started": "2023-04-14T04:59:51.713299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b177d0e-e7be-4e60-8489-0c9c299d973c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T04:59:54.567686Z",
     "iopub.status.busy": "2023-04-14T04:59:54.567273Z",
     "iopub.status.idle": "2023-04-14T05:08:03.480476Z",
     "shell.execute_reply": "2023-04-14T05:08:03.479090Z",
     "shell.execute_reply.started": "2023-04-14T04:59:54.567652Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (3.20.1)\n",
      "Collecting transformers==4.27.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6d/9b/2f536f9e73390209e0b27b74691355dac494b7ec8154f3012fdc6debbae7/transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting cpm_kernels\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/af/84/1831ce6ffa87b8fd4d9673c3595d0fc4e6631c0691eb43f406d3bf89b951/cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.10\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/89/5a/0d017d8d45cc309f9de8e5b8edc9b6b204d8c47936a3f2b84cf01650cf98/torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting gradio\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f0/be/fd3e87763d13936186016eceee874c3ecc55a69213e8cc18e800e5fbc4b3/gradio-3.26.0-py3-none-any.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mdtex2html\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/47/fa/5156a032ad68f6c32ae0dc3aaf8b3d690004b42497d4735a08bb4cea6ec3/mdtex2html-1.2.0-py3-none-any.whl (13 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ca/37/f0469a6f2a6a59074561d2214effec23ad9a2deac74cce467027f32167b4/sentencepiece-0.1.98-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4e/f2/017bf57106b845e31ef6179bf204042720a53629cf599ef9464da990e0e5/tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9e/6b/fdcd53aeee771a868c4187f0955116894a2b1e82d73fb5990c2ef63afc18/filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (1.23.4)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/74/71/abf5df0be7a29b6920d4ae85eb685584afbe84610631b70fe366b2857801/regex-2023.3.23-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (2.28.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/90/5ad98abead047169f4f86bc67e99020c841d71c9c6bd202e04af71e70e53/huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torch>=1.10->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/site-packages (from torch>=1.10->-r requirements.txt (line 4)) (2.8.7)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ea/6f/6d032cc1bb7db88a989ddce3f4968419a7edeafda362847f42f614b1f845/nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/55/92/914cdb650b6a5d1478f83148597a25e90ea37d739bd563c5096b0e8a5f43/nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e6/9d/dd0cdcd800e642e3c82ee3b5987c751afd4f3fb9cc2752517f42c3bc6e49/nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/23/d5/09493ff0e64fd77523afbbb075108f27a13790479efe86b9ffb4587671b5/nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/36/92/89cf558b514125d2ebd8344dd2f0533404b416486ff681d5434a5832a019/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ce/41/fdeb62b5437996e841d83d7d2714ca75b886547ee8017ee2fe6ea409d983/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8f/11/af78d54b2420e64a4dd19e704f5bb69dcb5a6a3138b4465d6a48cdf59a21/nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/4b/28142a3c70621cb3398ac626c276268ca87af50a3fa43667a834fa5d13bf/triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.8/site-packages (from torch>=1.10->-r requirements.txt (line 4)) (1.11.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ef/25/922c5996aada6611b79b53985af7999fc629aee1d5d001b6a22431e18fec/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/site-packages (from torch>=1.10->-r requirements.txt (line 4)) (3.1.2)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/74/79/b912a77e38e41f15a0581a59f5c3548d1ddfdda3225936fb67c342719e7a/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3e/77/66149e3153b19312fb782ea367f3f950123b93916a45538b573fe373570a/nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/dc/30/66d4347d6e864334da5bb1c7571305e501dcb11b9155971421bb7bb5315f/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10->-r requirements.txt (line 4)) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10->-r requirements.txt (line 4)) (65.4.1)\n",
      "Collecting lit\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ba/7f/981185aaea6ac3a4ae5de9eca143a6382e3c62c9ee9ad47cffe94f8181aa/lit-16.0.1.tar.gz (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cmake\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1d/de/48d485d12285cd53e322fb7bdb263778820984d4be54c2bb2fb5eced5e87/cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d2/e5/cef5eeb11d7e8bac830b3bee1c8311b19bf8e8a1c45fe14b876c70adcd06/aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting semantic-version\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: markupsafe in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 5)) (4.2.0)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/25/2d88e8feee8e055d015343f9b86e370a1ccbec546f2865c98397aaef24af/markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client==0.1.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/eb/5c/45e7af985d69aa94c9130d861192f539468acdfa928032243e08205f08ca/gradio_client-0.1.2-py3-none-any.whl (286 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 5)) (9.2.0)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 5)) (0.18.3)\n",
      "Collecting ffmpy\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/e2/947df4b3d666bfdd2b0c6355d215c45d2d40f929451cb29a8a2995b29788/ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 5)) (1.5.0)\n",
      "Collecting pydantic\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f1/bd/0dad4908e5f693b7951b68f435139ec583f5eebb3d75505e1efa0f2284fe/pydantic-1.10.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting orjson\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/21/14/e0f12fcf5e9ea20ddc0f65f4e30a89bc992dfce7cb7ed4fdfdc5854984be/orjson-3.8.10-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.4/271.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/8a/7bfea47c2a501c7bd57b56a3c458cf4882e55d41665ed93c8668a070ddad/websockets-11.0.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.0/130.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a8/76/635aa4f210d46ca105bfedd42d41f649b91d3e58422912726fc5e7965442/aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting httpx\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4e/c1/692013f1e6115a061a14f6c7d05947515a1eb7b85ef6e9bf0ffbf0e92738/httpx-0.24.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b4/ff/b1e11d8bffb5e0e1b6d27f402eeedbeb9be6df2cdbc09356a1ae49806dbf/python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mdit-py-plugins<=0.3.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/33/eb/c358112e8265f827cf8228eda36cf2a720ad933f5ca66f47f808edf4bb34/mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2e/84/d289e941ffec2f107d9097c8f7c2dbc874b0fc3fab9776aa3cc366d45ab2/fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (from gradio->-r requirements.txt (line 5)) (3.6.1)\n",
      "Collecting fsspec\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d6/30/db3078afe553e9a07c87534cbfb87a8c8ebb083fa0a8847ca5bdc86b51a7/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.8/site-packages (from mdtex2html->-r requirements.txt (line 6)) (3.4.1)\n",
      "Collecting latex2mathml\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/44/08/6c207389e184361c262a1f85819305cf264d01d0f4586604585897a70069/latex2mathml-3.75.2-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: toolz in /usr/local/lib/python3.8/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 5)) (0.11.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 5)) (4.16.0)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.8/site-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 5)) (0.4)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fa/1a/2280e2eb892162ef5c0480a131d1d176b61f5f24abdce8dd9862454f7d14/linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.27.1->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/site-packages (from pandas->gradio->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas->gradio->-r requirements.txt (line 5)) (2022.4)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (22.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b3/0d/0ba1f2022b9a36ae670c1f3c579ed08d0958398cb6beaf4687e606ad33d4/yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.1/262.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/0c/8469202f8f4b0e65816f91c3febc4bda7316c995b59ecdf3b15c574f7a24/multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ec/ab/a440db757401a1e8863c9abb374a77cb2884eda74ffbf555dedcf1fbe7f6/frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->gradio->-r requirements.txt (line 5)) (2.0.4)\n",
      "Collecting starlette<0.27.0,>=0.26.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/12/48/f9c1ec6bee313aba264fbc2483d9070f4e4526f2538e2b55b1e4a391d938/starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.8/site-packages (from httpx->gradio->-r requirements.txt (line 5)) (3.3)\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6c/39/05ebe30333ec66bba849d3c25c85d759b94c43bb03b2222de051c50d4390/httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/site-packages (from httpx->gradio->-r requirements.txt (line 5)) (2022.6.15)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.8/site-packages (from httpx->gradio->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/site-packages (from markdown->mdtex2html->-r requirements.txt (line 6)) (5.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib->gradio->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->transformers==4.27.1->-r requirements.txt (line 2)) (1.26.11)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/site-packages (from sympy->torch>=1.10->-r requirements.txt (line 4)) (1.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.8/site-packages (from uvicorn->gradio->-r requirements.txt (line 5)) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/site-packages (from uvicorn->gradio->-r requirements.txt (line 5)) (8.1.3)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.8/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 5)) (3.6.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown->mdtex2html->-r requirements.txt (line 6)) (3.9.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 5)) (5.10.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 5)) (0.18.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /usr/local/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 5)) (1.3.10)\n",
      "Collecting uc-micro-py\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/14/0e/738dbd15b1afe372d0d788e1e2112cfa67c9cf9e1c777360eaf9cd429caf/uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->gradio->-r requirements.txt (line 5)) (1.16.0)\n",
      "Building wheels for collected packages: ffmpy, lit\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=1f1971578a37f6d611042ad8286a1664be995c2183931d73adc9ff8d5fea04d3\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/df/de/5e20589ee5783667772dab48861912839245af96a4d69f4f14\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.1-py3-none-any.whl size=88173 sha256=3ebfc42a760049ed2d51912fa235dd9714037c45c874ca300a3f299eeb9c7d12\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/20/cf/d66fcd2bc1113f69a7287f477dbbd8821e55891921b11230ab\n",
      "Successfully built ffmpy lit\n",
      "Installing collected packages: tokenizers, sentencepiece, pydub, lit, ffmpy, cpm_kernels, cmake, websockets, uc-micro-py, semantic-version, regex, python-multipart, pydantic, orjson, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, multidict, mdurl, latex2mathml, fsspec, frozenlist, filelock, async-timeout, aiofiles, yarl, starlette, nvidia-cusolver-cu11, nvidia-cudnn-cu11, markdown-it-py, linkify-it-py, huggingface-hub, httpcore, aiosignal, transformers, mdtex2html, mdit-py-plugins, httpx, fastapi, aiohttp, gradio-client, gradio, triton, torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.2+cu111\n",
      "    Uninstalling torch-1.8.2+cu111:\n",
      "      Successfully uninstalled torch-1.8.2+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.9.2+cu111 requires torch==1.8.2, but you have torch 2.0.0 which is incompatible.\n",
      "torchaudio 0.8.2 requires torch==1.8.2, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 cmake-3.26.3 cpm_kernels-1.0.11 fastapi-0.95.1 ffmpy-0.3.0 filelock-3.11.0 frozenlist-1.3.3 fsspec-2023.4.0 gradio-3.26.0 gradio-client-0.1.2 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.13.4 latex2mathml-3.75.2 linkify-it-py-2.0.0 lit-16.0.1 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdtex2html-1.2.0 mdurl-0.1.2 multidict-6.0.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 orjson-3.8.10 pydantic-1.10.7 pydub-0.25.1 python-multipart-0.0.6 regex-2023.3.23 semantic-version-2.10.0 sentencepiece-0.1.98 starlette-0.26.1 tokenizers-0.13.3 torch-2.0.0 transformers-4.27.1 triton-2.0.0 uc-micro-py-1.0.1 websockets-11.0.1 yarl-1.8.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting rouge_chinese\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/03/0f/394cf877be7b903881020ef7217f7dc644dad158d52a9353fcab22e3464d/rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
      "Collecting nltk\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jieba\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/48/b7/6190994c06fb2cee1ff25c4326312a5c38c20e721424c332195f65af5190/datasets-2.11.0-py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting icetk\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/8a/731927e0901273815b779e6ce0e081a95ecf78835ff80be30830505ae06c/icetk-0.0.7-py3-none-any.whl (16 kB)\n",
      "Collecting accelerate\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e7/87/25dd46811431cfc5e8d6ba8c80758cb3131574b271fbf06cf1b691dba8d4/accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from rouge_chinese) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Collecting responses<0.19\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/site-packages (from datasets) (2.28.1)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5d/91/708bcf6e636fc4f1a07bdb704c0a320bafe9b83919cd501648307b31f555/pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/site-packages (from datasets) (1.5.0)\n",
      "Collecting multiprocess\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/13/95/8b875a678c6f9db81809dd5d6032e9f8628426e37f6aa6b7d404ba582de1/multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.8/site-packages (from datasets) (0.13.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/be/e3/a84bf2e561beed15813080d693b4b27573262433fced9c1d1fea59e60553/dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/site-packages (from datasets) (1.23.4)\n",
      "Collecting xxhash\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1a/d7/a42f83d34d4999321e06ca273f5e7bf7fa177154e29e0bfe455f3c66648d/xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.19\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c3/5c/5b6dcee0dcbd37862ef54023c6df405072c71cd06f5815b159a57f2c5070/protobuf-3.18.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.8/site-packages (from icetk) (0.1.98)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/site-packages (from icetk) (0.9.2+cu111)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from icetk) (3.11.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.8/site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/site-packages (from accelerate) (5.9.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (2.8.7)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate) (65.4.1)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.26.3)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas->datasets) (2022.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/site-packages (from torchvision->icetk) (9.2.0)\n",
      "Collecting torchvision\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ac/c7/c1fb8058c402e996e2cb4bcfc0fad362077da9e526c7e33e0e41a4a82f9d/torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/site-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/site-packages (from sympy->torch>=1.4.0->accelerate) (1.2.1)\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314459 sha256=a21127a502eab5e352b1bf134deaa4036e6c1696fad041b4e5ddef237c0c4267\n",
      "  Stored in directory: /root/.cache/pip/wheels/f3/30/86/64b88bf0241f0132806c61b1e2686b44f1327bfc5642f9d77d\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba, xxhash, rouge_chinese, pyarrow, protobuf, nltk, dill, responses, multiprocess, datasets, torchvision, icetk, accelerate\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.9.2+cu111\n",
      "    Uninstalling torchvision-0.9.2+cu111:\n",
      "      Successfully uninstalled torchvision-0.9.2+cu111\n",
      "Successfully installed accelerate-0.18.0 datasets-2.11.0 dill-0.3.6 icetk-0.0.7 jieba-0.42.1 multiprocess-0.70.14 nltk-3.8.1 protobuf-3.18.3 pyarrow-11.0.0 responses-0.18.0 rouge_chinese-1.0.3 torchvision-0.15.1 xxhash-3.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install rouge_chinese nltk jieba datasets icetk accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf71050-173d-43e2-b4c7-ea1bba5cefd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3cd575-fcb5-4a9d-ad57-e5ed3eb046f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T08:10:49.351631Z",
     "iopub.status.busy": "2023-04-13T08:10:49.350810Z",
     "iopub.status.idle": "2023-04-13T08:10:49.369688Z",
     "shell.execute_reply": "2023-04-13T08:10:49.368215Z",
     "shell.execute_reply.started": "2023-04-13T08:10:49.351547Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/ChatGLM-6B/ptuning\n"
     ]
    }
   ],
   "source": [
    "%cd ptuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1adb0a-6c1a-4619-8d0e-a3e279d77b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T08:46:51.370550Z",
     "iopub.status.busy": "2023-04-13T08:46:51.370139Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/13/2023 08:46:55 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "04/13/2023 08:46:55 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.02,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/output/ptuning/chatglm-6b-pt-128-2e-2/runs/Apr13_08-46-55_phodal-sbzt6z6u2q4h-main,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=3000,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/output/ptuning/chatglm-6b-pt-128-2e-2,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/output/ptuning/chatglm-6b-pt-128-2e-2,\n",
      "save_on_each_node=False,\n",
      "save_steps=1000,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-599b6231758ca161/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n",
      "Downloading data files: 100%|███████████████████| 2/2 [00:00<00:00, 2706.00it/s]\n",
      "Extracting data files: 100%|█████████████████████| 2/2 [00:00<00:00, 503.61it/s]\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-599b6231758ca161/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 684.78it/s]\n",
      "[INFO|configuration_utils.py:666] 2023-04-13 08:46:57,002 >> loading configuration file /openbayes/input/input1/config.json\n",
      "[WARNING|configuration_auto.py:905] 2023-04-13 08:46:57,002 >> Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "[INFO|configuration_utils.py:666] 2023-04-13 08:46:57,045 >> loading configuration file /openbayes/input/input1/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-13 08:46:57,046 >> Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"/openbayes/input/input1\",\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\"\n",
      "  },\n",
      "  \"bos_token_id\": 150004,\n",
      "  \"eos_token_id\": 150005,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"inner_hidden_size\": 16384,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"max_sequence_length\": 2048,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"pad_token_id\": 20003,\n",
      "  \"position_encoding_2d\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.27.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 150528\n",
      "}\n",
      "\n",
      "[WARNING|tokenization_auto.py:652] 2023-04-13 08:46:57,047 >> Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "[INFO|tokenization_utils_base.py:1800] 2023-04-13 08:46:57,213 >> loading file ice_text.model\n",
      "[INFO|tokenization_utils_base.py:1800] 2023-04-13 08:46:57,214 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:1800] 2023-04-13 08:46:57,214 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1800] 2023-04-13 08:46:57,214 >> loading file tokenizer_config.json\n",
      "[WARNING|auto_factory.py:456] 2023-04-13 08:46:58,505 >> Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "[INFO|modeling_utils.py:2400] 2023-04-13 08:46:58,582 >> loading weights file /openbayes/input/input1/pytorch_model.bin.index.json\n",
      "[INFO|configuration_utils.py:575] 2023-04-13 08:46:58,584 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 150004,\n",
      "  \"eos_token_id\": 150005,\n",
      "  \"pad_token_id\": 20003,\n",
      "  \"transformers_version\": \"4.27.1\"\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:09<00:00,  1.21s/it]\n",
      "[INFO|modeling_utils.py:3032] 2023-04-13 08:47:08,644 >> All model checkpoint weights were used when initializing ChatGLMForConditionalGeneration.\n",
      "\n",
      "[WARNING|modeling_utils.py:3034] 2023-04-13 08:47:08,645 >> Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at /openbayes/input/input1 and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|modeling_utils.py:2690] 2023-04-13 08:47:08,703 >> Generation config file not found, using a generation config created from the model config.\n",
      "/usr/local/lib/python3.8/site-packages/dill/_dill.py:1705: PicklingWarning: Cannot locate reference to <class 'google.protobuf.pyext._message.CMessage'>.\n",
      "  warnings.warn('Cannot locate reference to %r.' % (obj,), PicklingWarning)\n",
      "/usr/local/lib/python3.8/site-packages/dill/_dill.py:1707: PicklingWarning: Cannot pickle <class 'google.protobuf.pyext._message.CMessage'>: google.protobuf.pyext._message.CMessage has recursive self-references that trigger a RecursionError.\n",
      "  warnings.warn('Cannot pickle %r: %s.%s has recursive self-references that trigger a RecursionError.' % (obj, obj.__module__, obj_name), PicklingWarning)\n",
      "04/13/2023 08:47:08 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function_train at 0x7f9e594559d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "input_ids [45777, 20102, 37991, 20012, 45678, 20102, 21014, 20108, 40832, 20102, 33227, 150001, 150004, 20005, 20004, 84418, 84907, 20012, 83878, 92105, 83826, 87068, 88500, 83826, 89444, 20004, 90270, 45777, 20102, 37991, 20005, 84704, 93680, 20004, 115725, 92105, 83826, 87068, 88500, 83826, 89444, 20004, 136665, 83838, 84046, 84978, 93655, 83825, 88500, 83826, 89444, 20004, 20004, 25845, 20005, 20009, 20012, 20005, 118344, 92105, 83826, 87068, 88500, 83826, 89444, 20004, 90434, 20005, 84418, 85087, 45777, 20102, 37991, 20005, 84704, 20004, 83982, 20005, 84418, 86246, 92105, 83826, 87068, 88500, 83826, 89444, 90997, 20004, 85151, 20005, 84418, 89487, 88500, 83826, 89444, 83825, 95473, 20006, 83885, 83878, 87068, 97325, 88500, 83826, 89444, 150005, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003, 20003]\n",
      "inputs Animation and Comics:Browse and search for animations and comics \n",
      "用户故事:可以浏览和搜索动画和漫画\n",
      "作为一个 Animation and Comics 应用的用户\n",
      "我想要浏览和搜索动画和漫画\n",
      "以便于我能够找到我喜欢的动画和漫画\n",
      "\n",
      "AC 1: 用户可以浏览和搜索动画和漫画\n",
      "假设 用户打开 Animation and Comics 应用\n",
      "当 用户点击浏览和搜索动画和漫画按钮\n",
      "于是 用户可以看到动画和漫画的列表,并可以搜索特定的动画和漫画\n",
      "label_ids [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 150004, 20005, 20004, 84418, 84907, 20012, 83878, 92105, 83826, 87068, 88500, 83826, 89444, 20004, 90270, 45777, 20102, 37991, 20005, 84704, 93680, 20004, 115725, 92105, 83826, 87068, 88500, 83826, 89444, 20004, 136665, 83838, 84046, 84978, 93655, 83825, 88500, 83826, 89444, 20004, 20004, 25845, 20005, 20009, 20012, 20005, 118344, 92105, 83826, 87068, 88500, 83826, 89444, 20004, 90434, 20005, 84418, 85087, 45777, 20102, 37991, 20005, 84704, 20004, 83982, 20005, 84418, 86246, 92105, 83826, 87068, 88500, 83826, 89444, 90997, 20004, 85151, 20005, 84418, 89487, 88500, 83826, 89444, 83825, 95473, 20006, 83885, 83878, 87068, 97325, 88500, 83826, 89444, 150005, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "labels \n",
      "用户故事:可以浏览和搜索动画和漫画\n",
      "作为一个 Animation and Comics 应用的用户\n",
      "我想要浏览和搜索动画和漫画\n",
      "以便于我能够找到我喜欢的动画和漫画\n",
      "\n",
      "AC 1: 用户可以浏览和搜索动画和漫画\n",
      "假设 用户打开 Animation and Comics 应用\n",
      "当 用户点击浏览和搜索动画和漫画按钮\n",
      "于是 用户可以看到动画和漫画的列表,并可以搜索特定的动画和漫画\n",
      "/usr/local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]04/13/2023 08:47:22 - WARNING - transformers_modules.input1.modeling_chatglm - `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "{'loss': 2.0945, 'learning_rate': 0.019933333333333334, 'epoch': 0.05}          \n",
      "{'loss': 0.8312, 'learning_rate': 0.019866666666666668, 'epoch': 0.09}          \n",
      "{'loss': 0.6247, 'learning_rate': 0.0198, 'epoch': 0.14}                        \n",
      "{'loss': 0.4983, 'learning_rate': 0.019733333333333335, 'epoch': 0.19}          \n",
      "{'loss': 0.5578, 'learning_rate': 0.019666666666666666, 'epoch': 0.23}          \n",
      "{'loss': 0.4805, 'learning_rate': 0.0196, 'epoch': 0.28}                        \n",
      "{'loss': 0.5117, 'learning_rate': 0.019533333333333333, 'epoch': 0.33}          \n",
      "{'loss': 0.4679, 'learning_rate': 0.019466666666666667, 'epoch': 0.37}          \n",
      "{'loss': 0.4588, 'learning_rate': 0.0194, 'epoch': 0.42}                        \n",
      "{'loss': 0.409, 'learning_rate': 0.019333333333333334, 'epoch': 0.47}           \n",
      "{'loss': 0.4164, 'learning_rate': 0.019266666666666668, 'epoch': 0.51}          \n",
      "{'loss': 0.4337, 'learning_rate': 0.0192, 'epoch': 0.56}                        \n",
      "{'loss': 0.3902, 'learning_rate': 0.019133333333333332, 'epoch': 0.6}           \n",
      "{'loss': 0.43, 'learning_rate': 0.01906666666666667, 'epoch': 0.65}             \n",
      "{'loss': 0.4028, 'learning_rate': 0.019, 'epoch': 0.7}                          \n",
      "{'loss': 0.4197, 'learning_rate': 0.018933333333333333, 'epoch': 0.74}          \n",
      "{'loss': 0.3879, 'learning_rate': 0.018866666666666667, 'epoch': 0.79}          \n",
      "{'loss': 0.4018, 'learning_rate': 0.0188, 'epoch': 0.84}                        \n",
      "{'loss': 0.3771, 'learning_rate': 0.018733333333333334, 'epoch': 0.88}          \n",
      "{'loss': 0.3985, 'learning_rate': 0.018666666666666668, 'epoch': 0.93}          \n",
      "{'loss': 0.383, 'learning_rate': 0.018600000000000002, 'epoch': 0.98}           \n",
      "{'loss': 0.3544, 'learning_rate': 0.018533333333333332, 'epoch': 1.02}          \n",
      "{'loss': 0.3233, 'learning_rate': 0.018466666666666666, 'epoch': 1.07}          \n",
      "{'loss': 0.3058, 'learning_rate': 0.0184, 'epoch': 1.12}                        \n",
      "{'loss': 0.3259, 'learning_rate': 0.018333333333333333, 'epoch': 1.16}          \n",
      "{'loss': 0.3033, 'learning_rate': 0.018266666666666667, 'epoch': 1.21}          \n",
      "{'loss': 0.3264, 'learning_rate': 0.0182, 'epoch': 1.26}                        \n",
      "{'loss': 0.3009, 'learning_rate': 0.01813333333333333, 'epoch': 1.3}            \n",
      "{'loss': 0.3286, 'learning_rate': 0.01806666666666667, 'epoch': 1.35}           \n",
      "{'loss': 0.3067, 'learning_rate': 0.018000000000000002, 'epoch': 1.4}           \n",
      "{'loss': 0.3231, 'learning_rate': 0.017933333333333332, 'epoch': 1.44}          \n",
      "{'loss': 0.2918, 'learning_rate': 0.017866666666666666, 'epoch': 1.49}          \n",
      "{'loss': 0.2973, 'learning_rate': 0.0178, 'epoch': 1.53}                        \n",
      "{'loss': 0.2928, 'learning_rate': 0.017733333333333334, 'epoch': 1.58}          \n",
      "{'loss': 0.3132, 'learning_rate': 0.017666666666666667, 'epoch': 1.63}          \n",
      "{'loss': 0.2987, 'learning_rate': 0.0176, 'epoch': 1.67}                        \n",
      "{'loss': 0.3043, 'learning_rate': 0.017533333333333335, 'epoch': 1.72}          \n",
      "{'loss': 0.297, 'learning_rate': 0.017466666666666665, 'epoch': 1.77}           \n",
      "{'loss': 0.3116, 'learning_rate': 0.0174, 'epoch': 1.81}                        \n",
      "{'loss': 0.271, 'learning_rate': 0.017333333333333336, 'epoch': 1.86}           \n",
      "{'loss': 0.2672, 'learning_rate': 0.017266666666666666, 'epoch': 1.91}          \n",
      "{'loss': 0.2961, 'learning_rate': 0.0172, 'epoch': 1.95}                        \n",
      "{'loss': 0.281, 'learning_rate': 0.017133333333333334, 'epoch': 2.0}            \n",
      "{'loss': 0.216, 'learning_rate': 0.017066666666666667, 'epoch': 2.05}           \n",
      "{'loss': 0.2143, 'learning_rate': 0.017, 'epoch': 2.09}                         \n",
      "{'loss': 0.2124, 'learning_rate': 0.016933333333333335, 'epoch': 2.14}          \n",
      "{'loss': 0.2131, 'learning_rate': 0.01686666666666667, 'epoch': 2.19}           \n",
      "{'loss': 0.2242, 'learning_rate': 0.0168, 'epoch': 2.23}                        \n",
      "{'loss': 0.2179, 'learning_rate': 0.016733333333333333, 'epoch': 2.28}          \n",
      "{'loss': 0.2235, 'learning_rate': 0.016666666666666666, 'epoch': 2.33}          \n",
      "{'loss': 0.2103, 'learning_rate': 0.0166, 'epoch': 2.37}                        \n",
      "{'loss': 0.2057, 'learning_rate': 0.016533333333333334, 'epoch': 2.42}          \n",
      "{'loss': 0.2306, 'learning_rate': 0.016466666666666668, 'epoch': 2.47}          \n",
      "{'loss': 0.2282, 'learning_rate': 0.016399999999999998, 'epoch': 2.51}          \n",
      "{'loss': 0.2466, 'learning_rate': 0.01633333333333333, 'epoch': 2.56}           \n",
      "{'loss': 0.2345, 'learning_rate': 0.01626666666666667, 'epoch': 2.6}            \n",
      "{'loss': 0.2297, 'learning_rate': 0.016200000000000003, 'epoch': 2.65}          \n",
      "{'loss': 0.2188, 'learning_rate': 0.016133333333333333, 'epoch': 2.7}           \n",
      "{'loss': 0.2386, 'learning_rate': 0.016066666666666667, 'epoch': 2.74}          \n",
      "{'loss': 0.2121, 'learning_rate': 0.016, 'epoch': 2.79}                         \n",
      "{'loss': 0.2181, 'learning_rate': 0.015933333333333334, 'epoch': 2.84}          \n",
      "{'loss': 0.2152, 'learning_rate': 0.015866666666666668, 'epoch': 2.88}          \n",
      "{'loss': 0.2316, 'learning_rate': 0.0158, 'epoch': 2.93}                        \n",
      "{'loss': 0.233, 'learning_rate': 0.015733333333333332, 'epoch': 2.98}           \n",
      "{'loss': 0.1902, 'learning_rate': 0.015666666666666666, 'epoch': 3.02}          \n",
      "{'loss': 0.1536, 'learning_rate': 0.015600000000000001, 'epoch': 3.07}          \n",
      "{'loss': 0.1643, 'learning_rate': 0.015533333333333333, 'epoch': 3.12}          \n",
      "{'loss': 0.1536, 'learning_rate': 0.015466666666666667, 'epoch': 3.16}          \n",
      "{'loss': 0.1595, 'learning_rate': 0.0154, 'epoch': 3.21}                        \n",
      "{'loss': 0.165, 'learning_rate': 0.015333333333333334, 'epoch': 3.26}           \n",
      "{'loss': 0.1672, 'learning_rate': 0.015266666666666666, 'epoch': 3.3}           \n",
      "{'loss': 0.1602, 'learning_rate': 0.0152, 'epoch': 3.35}                        \n",
      "{'loss': 0.1638, 'learning_rate': 0.015133333333333334, 'epoch': 3.4}           \n",
      "{'loss': 0.1566, 'learning_rate': 0.015066666666666666, 'epoch': 3.44}          \n",
      "{'loss': 0.15, 'learning_rate': 0.015, 'epoch': 3.49}                           \n",
      "{'loss': 0.1668, 'learning_rate': 0.014933333333333335, 'epoch': 3.53}          \n",
      "{'loss': 0.1621, 'learning_rate': 0.014866666666666667, 'epoch': 3.58}          \n",
      "{'loss': 0.1653, 'learning_rate': 0.0148, 'epoch': 3.63}                        \n",
      "{'loss': 0.16, 'learning_rate': 0.014733333333333334, 'epoch': 3.67}            \n",
      "{'loss': 0.1505, 'learning_rate': 0.014666666666666666, 'epoch': 3.72}          \n",
      "{'loss': 0.1666, 'learning_rate': 0.0146, 'epoch': 3.77}                        \n",
      "{'loss': 0.1665, 'learning_rate': 0.014533333333333334, 'epoch': 3.81}          \n",
      "{'loss': 0.1613, 'learning_rate': 0.014466666666666668, 'epoch': 3.86}          \n",
      "{'loss': 0.1632, 'learning_rate': 0.0144, 'epoch': 3.91}                        \n",
      "{'loss': 0.1624, 'learning_rate': 0.014333333333333333, 'epoch': 3.95}          \n",
      "{'loss': 0.1723, 'learning_rate': 0.014266666666666667, 'epoch': 4.0}           \n",
      "{'loss': 0.1143, 'learning_rate': 0.014199999999999999, 'epoch': 4.05}          \n",
      "{'loss': 0.1093, 'learning_rate': 0.014133333333333333, 'epoch': 4.09}          \n",
      "{'loss': 0.1064, 'learning_rate': 0.014066666666666668, 'epoch': 4.14}          \n",
      "{'loss': 0.1126, 'learning_rate': 0.013999999999999999, 'epoch': 4.19}          \n",
      "{'loss': 0.1231, 'learning_rate': 0.013933333333333334, 'epoch': 4.23}          \n",
      "{'loss': 0.1176, 'learning_rate': 0.013866666666666668, 'epoch': 4.28}          \n",
      "{'loss': 0.1237, 'learning_rate': 0.0138, 'epoch': 4.33}                        \n",
      "{'loss': 0.1133, 'learning_rate': 0.013733333333333334, 'epoch': 4.37}          \n",
      "{'loss': 0.1105, 'learning_rate': 0.013666666666666667, 'epoch': 4.42}          \n",
      "{'loss': 0.1221, 'learning_rate': 0.013600000000000001, 'epoch': 4.47}          \n",
      "{'loss': 0.1093, 'learning_rate': 0.013533333333333333, 'epoch': 4.51}          \n",
      "{'loss': 0.1214, 'learning_rate': 0.013466666666666667, 'epoch': 4.56}          \n",
      "{'loss': 0.1202, 'learning_rate': 0.0134, 'epoch': 4.6}                         \n",
      "{'loss': 0.1226, 'learning_rate': 0.013333333333333332, 'epoch': 4.65}          \n",
      " 33%|███████████▋                       | 1000/3000 [1:33:44<3:07:30,  5.63s/it]Saving PrefixEncoder\n",
      "[INFO|configuration_utils.py:457] 2023-04-13 10:21:07,816 >> Configuration saved in /output/ptuning/chatglm-6b-pt-128-2e-2/checkpoint-1000/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-04-13 10:21:07,817 >> Configuration saved in /output/ptuning/chatglm-6b-pt-128-2e-2/checkpoint-1000/generation_config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-04-13 10:21:08,110 >> Model weights saved in /output/ptuning/chatglm-6b-pt-128-2e-2/checkpoint-1000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2163] 2023-04-13 10:21:08,111 >> tokenizer config file saved in /output/ptuning/chatglm-6b-pt-128-2e-2/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-04-13 10:21:08,112 >> Special tokens file saved in /output/ptuning/chatglm-6b-pt-128-2e-2/checkpoint-1000/special_tokens_map.json\n",
      "{'loss': 0.1205, 'learning_rate': 0.013266666666666666, 'epoch': 4.7}           \n",
      "{'loss': 0.1112, 'learning_rate': 0.013200000000000002, 'epoch': 4.74}          \n",
      "{'loss': 0.124, 'learning_rate': 0.013133333333333332, 'epoch': 4.79}           \n",
      "{'loss': 0.1161, 'learning_rate': 0.013066666666666667, 'epoch': 4.84}          \n",
      "{'loss': 0.1214, 'learning_rate': 0.013000000000000001, 'epoch': 4.88}          \n",
      "{'loss': 0.1277, 'learning_rate': 0.012933333333333333, 'epoch': 4.93}          \n",
      "{'loss': 0.1182, 'learning_rate': 0.012866666666666667, 'epoch': 4.98}          \n",
      "{'loss': 0.1056, 'learning_rate': 0.0128, 'epoch': 5.02}                        \n",
      "{'loss': 0.0855, 'learning_rate': 0.012733333333333334, 'epoch': 5.07}          \n",
      "{'loss': 0.0846, 'learning_rate': 0.012666666666666666, 'epoch': 5.12}          \n",
      "{'loss': 0.08, 'learning_rate': 0.0126, 'epoch': 5.16}                          \n",
      "{'loss': 0.0802, 'learning_rate': 0.012533333333333334, 'epoch': 5.21}          \n",
      "{'loss': 0.0851, 'learning_rate': 0.012466666666666666, 'epoch': 5.26}          \n",
      "{'loss': 0.0774, 'learning_rate': 0.0124, 'epoch': 5.3}                         \n",
      "{'loss': 0.0832, 'learning_rate': 0.012333333333333335, 'epoch': 5.35}          \n",
      "{'loss': 0.0815, 'learning_rate': 0.012266666666666665, 'epoch': 5.4}           \n",
      "{'loss': 0.0853, 'learning_rate': 0.0122, 'epoch': 5.44}                        \n",
      "{'loss': 0.0789, 'learning_rate': 0.012133333333333335, 'epoch': 5.49}          \n",
      "{'loss': 0.0871, 'learning_rate': 0.012066666666666668, 'epoch': 5.53}          \n",
      "{'loss': 0.0893, 'learning_rate': 0.012, 'epoch': 5.58}                         \n",
      "{'loss': 0.0929, 'learning_rate': 0.011933333333333334, 'epoch': 5.63}          \n",
      "{'loss': 0.0884, 'learning_rate': 0.011866666666666668, 'epoch': 5.67}          \n",
      "{'loss': 0.0954, 'learning_rate': 0.0118, 'epoch': 5.72}                        \n",
      "{'loss': 0.0913, 'learning_rate': 0.011733333333333333, 'epoch': 5.77}          \n",
      "{'loss': 0.0894, 'learning_rate': 0.011666666666666667, 'epoch': 5.81}          \n",
      "{'loss': 0.0952, 'learning_rate': 0.0116, 'epoch': 5.86}                        \n",
      "{'loss': 0.1017, 'learning_rate': 0.011533333333333333, 'epoch': 5.91}          \n",
      "{'loss': 0.0896, 'learning_rate': 0.011466666666666667, 'epoch': 5.95}          \n",
      "{'loss': 0.0815, 'learning_rate': 0.011399999999999999, 'epoch': 6.0}           \n",
      "{'loss': 0.0629, 'learning_rate': 0.011333333333333332, 'epoch': 6.05}          \n",
      "{'loss': 0.0642, 'learning_rate': 0.011266666666666668, 'epoch': 6.09}          \n",
      "{'loss': 0.0567, 'learning_rate': 0.011200000000000002, 'epoch': 6.14}          \n",
      "{'loss': 0.0618, 'learning_rate': 0.011133333333333334, 'epoch': 6.19}          \n",
      "{'loss': 0.0628, 'learning_rate': 0.011066666666666667, 'epoch': 6.23}          \n",
      "{'loss': 0.0649, 'learning_rate': 0.011000000000000001, 'epoch': 6.28}          \n",
      "{'loss': 0.0593, 'learning_rate': 0.010933333333333333, 'epoch': 6.33}          \n",
      "{'loss': 0.061, 'learning_rate': 0.010866666666666667, 'epoch': 6.37}           \n",
      "{'loss': 0.0613, 'learning_rate': 0.0108, 'epoch': 6.42}                        \n",
      "{'loss': 0.0649, 'learning_rate': 0.010733333333333333, 'epoch': 6.47}          \n",
      "{'loss': 0.0649, 'learning_rate': 0.010666666666666666, 'epoch': 6.51}          \n",
      "{'loss': 0.0615, 'learning_rate': 0.0106, 'epoch': 6.56}                        \n",
      "{'loss': 0.0665, 'learning_rate': 0.010533333333333332, 'epoch': 6.6}           \n",
      "{'loss': 0.0742, 'learning_rate': 0.010466666666666666, 'epoch': 6.65}          \n",
      "{'loss': 0.0678, 'learning_rate': 0.010400000000000001, 'epoch': 6.7}           \n",
      "{'loss': 0.068, 'learning_rate': 0.010333333333333335, 'epoch': 6.74}           \n",
      "{'loss': 0.0687, 'learning_rate': 0.010266666666666667, 'epoch': 6.79}          \n",
      "{'loss': 0.0662, 'learning_rate': 0.0102, 'epoch': 6.84}                        \n",
      "{'loss': 0.0692, 'learning_rate': 0.010133333333333334, 'epoch': 6.88}          \n",
      "{'loss': 0.0629, 'learning_rate': 0.010066666666666666, 'epoch': 6.93}          \n",
      "{'loss': 0.0686, 'learning_rate': 0.01, 'epoch': 6.98}                          \n",
      "{'loss': 0.0618, 'learning_rate': 0.009933333333333334, 'epoch': 7.02}          \n",
      "{'loss': 0.0494, 'learning_rate': 0.009866666666666668, 'epoch': 7.07}          \n",
      "{'loss': 0.0504, 'learning_rate': 0.0098, 'epoch': 7.12}                        \n",
      "{'loss': 0.0481, 'learning_rate': 0.009733333333333333, 'epoch': 7.16}          \n",
      "{'loss': 0.0448, 'learning_rate': 0.009666666666666667, 'epoch': 7.21}          \n",
      "{'loss': 0.046, 'learning_rate': 0.0096, 'epoch': 7.26}                         \n",
      "{'loss': 0.0442, 'learning_rate': 0.009533333333333335, 'epoch': 7.3}           \n",
      "{'loss': 0.0475, 'learning_rate': 0.009466666666666667, 'epoch': 7.35}          \n",
      "{'loss': 0.0459, 'learning_rate': 0.0094, 'epoch': 7.4}                         \n",
      "{'loss': 0.0517, 'learning_rate': 0.009333333333333334, 'epoch': 7.44}          \n",
      "{'loss': 0.0504, 'learning_rate': 0.009266666666666666, 'epoch': 7.49}          \n",
      "{'loss': 0.0459, 'learning_rate': 0.0092, 'epoch': 7.53}                        \n",
      "{'loss': 0.0473, 'learning_rate': 0.009133333333333334, 'epoch': 7.58}          \n",
      "{'loss': 0.0487, 'learning_rate': 0.009066666666666666, 'epoch': 7.63}          \n",
      "{'loss': 0.0547, 'learning_rate': 0.009000000000000001, 'epoch': 7.67}          \n",
      "{'loss': 0.0505, 'learning_rate': 0.008933333333333333, 'epoch': 7.72}          \n",
      "{'loss': 0.0495, 'learning_rate': 0.008866666666666667, 'epoch': 7.77}          \n",
      "{'loss': 0.0571, 'learning_rate': 0.0088, 'epoch': 7.81}                        \n",
      "{'loss': 0.0531, 'learning_rate': 0.008733333333333333, 'epoch': 7.86}          \n",
      "{'loss': 0.0531, 'learning_rate': 0.008666666666666668, 'epoch': 7.91}          \n",
      "{'loss': 0.0501, 'learning_rate': 0.0086, 'epoch': 7.95}                        \n",
      "{'loss': 0.05, 'learning_rate': 0.008533333333333334, 'epoch': 8.0}             \n",
      "{'loss': 0.0388, 'learning_rate': 0.008466666666666667, 'epoch': 8.05}          \n",
      "{'loss': 0.0362, 'learning_rate': 0.0084, 'epoch': 8.09}                        \n",
      "{'loss': 0.0379, 'learning_rate': 0.008333333333333333, 'epoch': 8.14}          \n",
      "{'loss': 0.0363, 'learning_rate': 0.008266666666666667, 'epoch': 8.19}          \n",
      "{'loss': 0.0349, 'learning_rate': 0.008199999999999999, 'epoch': 8.23}          \n",
      "{'loss': 0.0354, 'learning_rate': 0.008133333333333334, 'epoch': 8.28}          \n",
      "{'loss': 0.0346, 'learning_rate': 0.008066666666666666, 'epoch': 8.33}          \n",
      "{'loss': 0.0386, 'learning_rate': 0.008, 'epoch': 8.37}                         \n",
      "{'loss': 0.0397, 'learning_rate': 0.007933333333333334, 'epoch': 8.42}          \n",
      "{'loss': 0.0377, 'learning_rate': 0.007866666666666666, 'epoch': 8.47}          \n",
      "{'loss': 0.0404, 'learning_rate': 0.0078000000000000005, 'epoch': 8.51}         \n",
      "{'loss': 0.041, 'learning_rate': 0.007733333333333333, 'epoch': 8.56}           \n",
      "{'loss': 0.0417, 'learning_rate': 0.007666666666666667, 'epoch': 8.6}           \n",
      "{'loss': 0.0382, 'learning_rate': 0.0076, 'epoch': 8.65}                        \n",
      "{'loss': 0.0376, 'learning_rate': 0.007533333333333333, 'epoch': 8.7}           \n",
      "{'loss': 0.0383, 'learning_rate': 0.0074666666666666675, 'epoch': 8.74}         \n",
      " 63%|█████████████████████▉             | 1884/3000 [2:56:40<1:44:47,  5.63s/it]"
     ]
    }
   ],
   "source": [
    "!mkdir -p /output/train\n",
    "!sed -n '10,15p' /openbayes/input/input0/datasets/userstory/userstory_detail_double_clean_cn.jsonl > /output/train/dev.json\n",
    "!cp /openbayes/input/input0/datasets/userstory/userstory_detail_double_clean_cn.jsonl /output/train/train.json\n",
    "!export CUDA_VISIBLE_DEVICES=0 && python main.py \\\n",
    "    --do_train \\\n",
    "    --train_file /output/train/train.json \\\n",
    "    --validation_file /output/train/dev.json \\\n",
    "    --prompt_column input \\\n",
    "    --response_column output \\\n",
    "    --overwrite_cache \\\n",
    "    --model_name_or_path /openbayes/input/input1 \\\n",
    "    --output_dir /output/ptuning/chatglm-6b-pt-128-2e-2 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --max_source_length 512 \\\n",
    "    --max_target_length 512 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --gradient_accumulation_steps 2 \\\n",
    "    --predict_with_generate \\\n",
    "    --max_steps 3000 \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 1000 \\\n",
    "    --learning_rate 2e-2 \\\n",
    "    --pre_seq_len 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2077e85c-bfef-4920-80b8-00d4af95a8c3",
   "metadata": {},
   "source": [
    "# 训练后推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89915aba-7e30-42a4-a91a-26bde92f2a2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T05:08:14.712302Z",
     "iopub.status.busy": "2023-04-14T05:08:14.712060Z",
     "iopub.status.idle": "2023-04-14T05:08:37.382896Z",
     "shell.execute_reply": "2023-04-14T05:08:37.382131Z",
     "shell.execute_reply.started": "2023-04-14T05:08:14.712280Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234478ba80b74c978987dcea2b6e3b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at /openbayes/input/input1 and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "# 载入Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/openbayes/input/input1\", trust_remote_code=True)\n",
    "config = AutoConfig.from_pretrained(\"/openbayes/input/input1\", trust_remote_code=True, pre_seq_len=128)\n",
    "model = AutoModel.from_pretrained(\"/openbayes/input/input1\", config=config, trust_remote_code=True)\n",
    "prefix_state_dict = torch.load(os.path.join(\"/output/ptuning/chatglm-6b-pt-128-2e-2/checkpoint-3000\", \"pytorch_model.bin\"))\n",
    "new_prefix_state_dict = {}\n",
    "for k, v in prefix_state_dict.items():\n",
    "    if k.startswith(\"transformer.prefix_encoder.\"):\n",
    "        new_prefix_state_dict[k[len(\"transformer.prefix_encoder.\"):]] = v\n",
    "model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)\n",
    "model = model.half().cuda()\n",
    "model.transformer.prefix_encoder.float()\n",
    "model = model.eval()\n",
    "\n",
    "def evaluate(prompt):\n",
    "    response, history = model.chat(tokenizer, prompt, history=[])\n",
    "    print(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e7a2212-08f2-4271-969c-7f4efb10ec6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T03:01:46.992787Z",
     "iopub.status.busy": "2023-04-14T03:01:46.992396Z",
     "iopub.status.idle": "2023-04-14T03:01:49.844576Z",
     "shell.execute_reply": "2023-04-14T03:01:49.843580Z",
     "shell.execute_reply.started": "2023-04-14T03:01:46.992759Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "京西商城:浏览最新电影\n",
      "用户故事：可以浏览最新电影\n",
      "作为一个京西商城的用户\n",
      "我想在应用中浏览最新电影\n",
      "以便于我能够及时观看最新的电影\n",
      "\n",
      "AC 1: 用户可以在应用中浏览最新电影\n",
      "假设 用户已经登录了京西商城\n",
      "当 用户点击浏览最新电影按钮\n",
      "于是 用户可以看到最新的电影列表，并且可以搜索特定的电影\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"京西商城:浏览最新电影\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6ade17e-d507-4b12-8805-e609403ce4b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-14T05:15:49.086509Z",
     "iopub.status.busy": "2023-04-14T05:15:49.086205Z",
     "iopub.status.idle": "2023-04-14T05:16:31.166921Z",
     "shell.execute_reply": "2023-04-14T05:16:31.166251Z",
     "shell.execute_reply.started": "2023-04-14T05:15:49.086487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电商平台: 用户可以在平台上搜索、购买和评价各种商品，商家可以在平台上开设店铺、发布商品和管理订单。\n",
      "用户故事：可以在电商平台上搜索、购买和评价各种商品\n",
      "作为一个电商平台的用户\n",
      "我想在平台上搜索、购买和评价各种商品\n",
      "以便于我能够更好地了解和购买各种商品\n",
      "\n",
      "AC 1: 用户可以在电商平台上搜索、购买和评价各种商品\n",
      "假设 用户已经登录电商平台\n",
      "当 用户搜索到自己想要的商品\n",
      "于是 用户可以购买该商品，并且可以评价该商品\n",
      "====================================================\n",
      "在线教育: 学生可以通过在线课程和教材学习知识，老师可以在平台上创建课程和监督学生进度。\n",
      "用户故事：可以通过在线教育平台学习知识\n",
      "作为一个在线教育平台的用户\n",
      "我想通过在线教育平台学习知识\n",
      "以便于我可以通过在线课程和教材学习知识\n",
      "\n",
      "AC 1: 用户可以通过在线教育平台学习知识\n",
      "假设 用户已经登录到在线教育平台\n",
      "当 用户点击学习按钮\n",
      "于是 用户可以通过在线课程和教材学习知识\n",
      "\n",
      "AC 2: 用户可以在在线教育平台上创建课程\n",
      "假设 用户已经登录到在线教育平台\n",
      "当 用户点击创建课程按钮\n",
      "于是 用户可以在平台上创建课程，并和监督学生进度\n",
      "====================================================\n",
      "社交媒体: 用户可以在平台上分享动态、发表观点和交流信息，平台可以通过广告等方式盈利。\n",
      "用户可以使用社交媒体平台分享动态、发表观点和交流信息\n",
      "作为一个社交媒体用户\n",
      "我想在平台上分享动态、发表观点和交流信息\n",
      "以便于我可以与其他用户进行交流，并获得反馈\n",
      "\n",
      "AC 1: 社交媒体用户可以分享动态、发表观点和交流信息\n",
      "假设 社交媒体用户已经登录\n",
      "当 社交媒体用户点击分享动态按钮\n",
      "于是 社交媒体用户可以将动态分享到平台上\n",
      "\n",
      "AC 2: 社交媒体用户可以发表观点和交流信息\n",
      "假设 社交媒体用户已经登录\n",
      "当 社交媒体用户点击发表观点按钮\n",
      "于是 社交媒体用户可以发表观点和交流信息\n",
      "====================================================\n",
      "金融科技: 用户可以在应用上进行在线支付、理财和投资，平台可以提供风险评估、信用评分等服务。\n",
      "用户可以使用金融科技应用进行在线支付、理财和投资\n",
      "作为一个金融科技应用的用户\n",
      "我可以在应用上进行在线支付、理财和投资\n",
      "同时，平台可以提供风险评估、信用评分等服务\n",
      "\n",
      "AC 1: 用户可以在应用上进行在线支付、理财和投资\n",
      "假设 用户已经登录了应用\n",
      "当 用户点击在线支付、理财和投资按钮\n",
      "于是 用户可以在应用上进行在线支付、理财和投资\n",
      "====================================================\n",
      "医疗保健: 用户可以通过在线平台寻找医生、预约挂号和购买药品，平台可以提供健康咨询和智能诊断服务。\n",
      "用户可以通过医疗保健应用寻找医生、预约挂号和购买药品\n",
      "作为一个医疗保健应用的用户\n",
      "我想通过医疗保健应用寻找医生、预约挂号和购买药品\n",
      "以便于我能够及时获取医疗服务和药品信息\n",
      "\n",
      "AC 1: 用户可以在医疗保健应用中寻找医生\n",
      "假设 用户在医疗保健应用中搜索医生\n",
      "当 用户找到符合条件的医生\n",
      "于是 用户可以预约医生就诊\n",
      "====================================================\n",
      "酒店预订: 用户可以在平台上搜索、预订和评价酒店房间，酒店可以在平台上展示房间信息和管理订单。\n",
      "用户故事：可以在酒店预订平台上搜索、预订和评价酒店房间\n",
      "作为一个酒店预订用户\n",
      "我想在酒店预订平台上搜索、预订和评价酒店房间\n",
      "以便于我能够更好地了解酒店的房间信息，并且可以给出自己的评价\n",
      "\n",
      "AC 1: 用户可以在酒店预订平台上搜索、预订和评价酒店房间\n",
      "假设 用户已经登录了酒店预订应用\n",
      "当 用户在平台上搜索、预订和评价酒店房间\n",
      "于是 用户可以查看酒店的房间信息，并且可以给出自己的评价\n",
      "====================================================\n",
      "物流配送: 用户可以在平台上提交物流订单、查询物流状态和评价服务质量，物流公司可以通过平台管理订单和分配配送员。\n",
      "用户故事：可以在物流配送应用中提交物流订单、查询物流状态和评价服务质量\n",
      "作为一个物流配送的用户\n",
      "我想在物流配送应用中提交物流订单、查询物流状态和评价服务质量\n",
      "以便于我能够更好地掌握物流订单的进度，并且能够对服务质量进行评价。\n",
      "\n",
      "AC 1: 用户可以在物流配送应用中提交物流订单、查询物流状态和评价服务质量\n",
      "AC 2: 物流公司可以通过平台管理订单和分配配送员\n",
      "AC 3: 用户可以在物流配送应用中查看物流订单的进度\n",
      "AC 4: 用户可以在物流配送应用中查看物流状态的更新\n",
      "AC 5: 用户可以在物流配送应用中查看评价服务质量的反馈\n",
      "====================================================\n",
      "电子商务: 商家可以通过平台上发布商品、管理订单和进行促销活动，用户可以在平台上浏览商品和下单购买。\n",
      "用户故事：可以在电子商务应用中发布商品、管理订单和进行促销活动\n",
      "作为一个电子商务应用的用户\n",
      "我想在应用中发布商品、管理订单和进行促销活动\n",
      "以便于我可以购买我想要的商品\n",
      "\n",
      "AC 1: 用户可以在电子商务应用中发布商品\n",
      "假设 用户已经登录应用\n",
      "当 用户点击发布商品按钮\n",
      "于是 用户可以在应用中发布商品\n",
      "\n",
      "AC 2: 用户可以在电子商务应用中管理订单\n",
      "假设 用户已经登录应用\n",
      "当 用户点击管理订单按钮\n",
      "于是 用户可以在应用中管理订单\n",
      "\n",
      "AC 3: 用户可以在电子商务应用中进行促销活动\n",
      "假设 用户已经登录应用\n",
      "当 用户点击进行促销活动按钮\n",
      "于是 用户可以在应用中进行促销活动\n",
      "====================================================\n",
      "在线旅游: 用户可以在平台上搜索旅游线路、预订酒店和门票，旅行社可以在平台上展示旅游产品和管理订单。\n",
      "用户故事：可以在平台上搜索旅游线路、预订酒店和门票\n",
      "作为一个旅游者\n",
      "我想在平台上搜索旅游线路、预订酒店和门票\n",
      "以便于我可以根据自己的需求找到合适的旅游线路，预订合适的酒店和门票。\n",
      "\n",
      "AC 1: 旅游者可以在平台上搜索旅游线路、预订酒店和门票\n",
      "假设 旅游者已经登录了平台\n",
      "当 旅游者在平台上搜索旅游线路、预订酒店和门票\n",
      "于是 旅游者可以看到合适的旅游线路，预订合适的酒店和门票。\n",
      "\n",
      "AC 2: 旅游者可以在平台上查看旅游线路的详细信息\n",
      "假设 旅游者已经登录了平台\n",
      "当 旅游者在平台上搜索旅游线路\n",
      "于是 旅游者可以看到旅游线路的详细信息，包括旅游线路的时间、地点、价格等。\n",
      "====================================================\n",
      "职业社交: 用户可以在平台上创建个人资料、搜索职位和建立职业关系，企业可以在平台上发布招聘信息和筛选候选人。\n",
      "用户可以使用职业社交应用创建个人资料、搜索职位和建立职业关系\n",
      "作为一个职业社交应用的用户\n",
      "我想在应用中创建个人资料、搜索职位和建立职业关系\n",
      "以便于我可以在应用中找到合适的工作机会，并且可以建立稳定的职业关系。\n",
      "\n",
      "AC 1: 用户可以在应用中创建个人资料\n",
      "假设 用户已经登录应用\n",
      "当 用户点击创建个人资料按钮\n",
      "于是 用户可以通过应用创建个人资料，并且可以添加个人信息、职业背景、技能等。\n",
      "\n",
      "AC 2: 用户可以在应用中搜索职位\n",
      "假设 用户已经登录应用\n",
      "当 用户点击搜索职位按钮\n",
      "于是 用户可以在应用中搜索职位，并且可以查看职位的详细信息，以及职位要求的专业技能和条件等。\n",
      "\n",
      "AC 3: 用户可以在应用中建立职业关系\n",
      "假设 用户已经登录应用\n",
      "当 用户点击建立职业关系按钮\n",
      "于是 用户可以在应用中搜索合适的候选人，并且可以查看候选人的个人资料、技能、工作经历等，以便选择合适的候选人。\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/output/train/evaluate.jsonl', 'r', encoding='utf-8') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "    evaluate(result[\"input\"])\n",
    "    print(\"====================================================\\r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
